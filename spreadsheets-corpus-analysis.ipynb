{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31bd8976-b30f-4264-b61f-ab6db3afe9c8",
   "metadata": {},
   "source": [
    "# Analyze metadata from Zenodo spreadsheets corpus\n",
    "Code to calculate file sizes, analyze file names, and generate lists of record ids for file downloading and corpus sampling related to testing and interview sampling frames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b64cb-1e47-4934-be26-8f8a4f551b26",
   "metadata": {},
   "source": [
    "## Imports and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6028b5-1442-4143-b19a-04b40701b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import edtf\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "from edtf import parse_edtf, struct_time_to_date\n",
    "from caseutil import get_cases\n",
    "import regex\n",
    "from langdetect import detect_langs\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from langdetect import DetectorFactory # Important for consistency\n",
    "import swifter\n",
    "from itertools import combinations\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ade28a-180a-44a4-9b06-645c59819cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function by Peter F: https://stackoverflow.com/questions/5194057/better-way-to-convert-file-sizes-in-python\n",
    "#Zenodo seems to calculate based on SI=True\n",
    "def format_bytes(bytes, unit, SI=False):\n",
    "    \"\"\"\n",
    "    Converts bytes to common units such as kb, kib, KB, mb, mib, MB\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    bytes: int\n",
    "        Number of bytes to be converted\n",
    "\n",
    "    unit: str\n",
    "        Desired unit of measure for output\n",
    "\n",
    "\n",
    "    SI: bool\n",
    "        True -> Use SI standard e.g. KB = 1000 bytes\n",
    "        False -> Use JEDEC standard e.g. KB = 1024 bytes\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str:\n",
    "        E.g. \"7 MiB\" where MiB is the original unit abbreviation supplied\n",
    "    \"\"\"\n",
    "    if unit.lower() in \"b bit bits\".split():\n",
    "        return f\"{bytes*8} {unit}\"\n",
    "    unitN = unit[0].upper()+unit[1:].replace(\"s\",\"\")  # Normalised\n",
    "    reference = {\"Kb Kib Kibibit Kilobit\": (7, 1),\n",
    "                 \"KB KiB Kibibyte Kilobyte\": (10, 1),\n",
    "                 \"Mb Mib Mebibit Megabit\": (17, 2),\n",
    "                 \"MB MiB Mebibyte Megabyte\": (20, 2),\n",
    "                 \"Gb Gib Gibibit Gigabit\": (27, 3),\n",
    "                 \"GB GiB Gibibyte Gigabyte\": (30, 3),\n",
    "                 \"Tb Tib Tebibit Terabit\": (37, 4),\n",
    "                 \"TB TiB Tebibyte Terabyte\": (40, 4),\n",
    "                 \"Pb Pib Pebibit Petabit\": (47, 5),\n",
    "                 \"PB PiB Pebibyte Petabyte\": (50, 5),\n",
    "                 \"Eb Eib Exbibit Exabit\": (57, 6),\n",
    "                 \"EB EiB Exbibyte Exabyte\": (60, 6),\n",
    "                 \"Zb Zib Zebibit Zettabit\": (67, 7),\n",
    "                 \"ZB ZiB Zebibyte Zettabyte\": (70, 7),\n",
    "                 \"Yb Yib Yobibit Yottabit\": (77, 8),\n",
    "                 \"YB YiB Yobibyte Yottabyte\": (80, 8),\n",
    "                 }\n",
    "    key_list = '\\n'.join([\"     b Bit\"] + [x for x in reference.keys()]) +\"\\n\"\n",
    "    if unitN not in key_list:\n",
    "        raise IndexError(f\"\\n\\nConversion unit must be one of:\\n\\n{key_list}\")\n",
    "    units, divisors = [(k,v) for k,v in reference.items() if unitN in k][0]\n",
    "    if SI:\n",
    "        divisor = 1000**divisors[1]/8 if \"bit\" in units else 1000**divisors[1]\n",
    "    else:\n",
    "        divisor = float(1 << divisors[0])\n",
    "    value = bytes / divisor\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d2e5e-7d0e-4dcc-9924-93834e8c3b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function using the edtf library to parse the metadata.publication_date field, since it is in EDTF form.\n",
    "#finds the earlier date if there is a date range and extracts the year\n",
    "def parseable_date(x):\n",
    "    y = parse_edtf(x)\n",
    "    z = struct_time_to_date(y.lower_strict()).year\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69681498-2652-4607-901b-858257aab553",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that uses caseutil to try to guess the case of the string\n",
    "def filename_cases(x):\n",
    "    cases = get_cases(x)\n",
    "    cases_string = ';'.join(cases)\n",
    "    return cases_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0cb802-7385-454c-8307-4d30f6164def",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.w3schools.in/python/examples/language-detection\n",
    "#https://stackoverflow.com/questions/39142778/how-to-determine-the-language-of-a-piece-of-text\n",
    "#original takes forever to run\n",
    "#asked Google Gemini to optimize; Gemini also recommended using swifter\n",
    "#prompt: Can you optimize this Python function that uses the langdetect library? \n",
    "# and then I am implementing this in a large pandas dataframe. What changes would you make so that it processes faster?\n",
    "\n",
    "# from langdetect import detect_langs\n",
    "# from langdetect.lang_detect_exception import LangDetectException\n",
    "# from langdetect import DetectorFactory # Important for consistency\n",
    "\n",
    "# Set a seed once at the beginning of your script/application\n",
    "DetectorFactory.seed = 0\n",
    "\n",
    "def detect_lang(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return 'no-lang' # Handle non-string or empty/whitespace-only input early\n",
    "\n",
    "    try:\n",
    "        languages = detect_langs(text)\n",
    "        # Use a list comprehension for efficient string building\n",
    "        lang_parts = [f\"{lang.lang};{lang.prob:.4f}\" for lang in languages] # Format probability\n",
    "        return '|'.join(lang_parts)\n",
    "    except LangDetectException:\n",
    "        return 'no-lang'\n",
    "    except Exception as e:\n",
    "        # Log unexpected errors for debugging, but return 'no-lang' for consistency\n",
    "        # import logging\n",
    "        # logging.error(f\"Unexpected error for text '{text}': {e}\")\n",
    "        return 'no-lang'\n",
    "\n",
    "# original attempt:\n",
    "#def detect_lang(x):\n",
    "#     try:\n",
    "#         languages = detect_langs(x)\n",
    "#         lang_string = ''\n",
    "#         for language in languages:\n",
    "#             lang_code = language.lang\n",
    "#             #print(lang_code)\n",
    "#             lang_prob = str(language.prob)\n",
    "#             #print(lang_prob)\n",
    "#             lang_string += lang_code +';'+lang_prob +'|'\n",
    "#         return lang_string\n",
    "#     except Exception as e:\n",
    "#         return 'no-lang'\n",
    "# Sample Output:\n",
    "# en 0.50 (English)\n",
    "# hi 0.50 (Hindi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be80cad-14b5-4691-9865-813f1f29b3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/25628973/capturing-named-groups-in-regex-with-re-findall\n",
    "#used Google Gemini Flash 2.5 to modify this code and use sets instead of lists and to concatenate the string\n",
    "def filename_capitalization(x):\n",
    "\n",
    "    match = regex.findall(r'(?P<lower>\\p{Ll})|(?P<upper>\\p{Lu})|(?P<digit>\\d)', x, re.UNICODE)\n",
    "    capitalization_types=set()\n",
    "    \n",
    "    for tup in match:\n",
    "        if tup[0] != '':\n",
    "            capitalization_types.add('lower')\n",
    "        if tup[1] != '':\n",
    "            capitalization_types.add('upper')\n",
    "        if tup[2] != '':\n",
    "            capitalization_types.add('digit')\n",
    "    capitalization_list=list(capitalization_types)\n",
    "    capitalization_list.sort()\n",
    "    concatenated_string = ';'.join(capitalization_list)\n",
    "    return concatenated_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716b31a5-2fe8-4573-933b-4df36efd2ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the global option to prevent scientific notation in aggregation and other derivative dataframes.\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b91332-67a4-48fe-97b4-09016d2dc193",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2854a-7076-4efa-9182-7965cbedea88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the API results, which filtered filetype:(csv OR xlsx OR tsv OR xls OR ods OR xlsb OR ots OR xlsm OR xltm OR xltx OR ogw) AND doi:zenodo AND created:{date}\n",
    "with open('zenodo_API_metadata_results_2025-11-05_03-38_PM.json', 'r') as f:\n",
    "#with open('zenodo_snippet.json', 'r') as f:\n",
    "    data = f.read()\n",
    "zenodo_dict = json.loads(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999a42e7-1afa-4c29-a262-7841e53756b2",
   "metadata": {},
   "source": [
    "## Create dataframes for metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75900f-4741-4de6-a62c-1d4731863f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe that contains all of the JSON API result, including some fields that contain nested JSON\n",
    "zenodo_df = pd.json_normalize(zenodo_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e4dab-369b-4339-87f0-35cf13fb8285",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab96dac-2e81-4e3b-a68d-f6948e9933db",
   "metadata": {},
   "source": [
    "### Find duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff96df-706a-447f-9326-ce6d474006e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many unique ids are there?\n",
    "len(zenodo_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2006b1c2-cba5-4a66-a383-9bc07a1ebb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#does not work because some columns contain lists.\n",
    "#zenodo_df.duplicated(keep=False).sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe498e-068f-4456-928d-96f0ae8f1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find duplicate records, comparing all fields. since come columns contain lists, have to treat df as string\n",
    "##https://stackoverflow.com/questions/43855462/pandas-drop-duplicates-method-not-working-on-dataframe-containing-lists\n",
    "zenodo_dupes_1 = zenodo_df.loc[zenodo_df.astype(str).duplicated(keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10851a3-4b32-4d91-9483-18508576f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find duplicate records, comparing only id\n",
    "zenodo_dupes_2 = zenodo_df.loc[zenodo_df.duplicated(subset='id', keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e486f69-e755-40e1-b46f-8c6074686ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export files so the two lists of duplicates can be compared, and can figure out why some duplicates are not being found when all rows are compared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df086f15-24bb-47be-8837-e363811291d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_dupes_1.to_csv(f'zenodo_dupes_1_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf84563-382c-4346-9306-0d368924a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_dupes_2.to_csv(f'zenodo_dupes_2_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b8158-f025-4959-91f8-faeed5f20bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turns out it is because of download stats!\n",
    "#get a list of column headers that excludes the stats cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d13dbc-94db-486e-87d2-a7d6aa23f4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_columns = zenodo_df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ed846f-3398-42ef-b557-93a6ee50520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a9fd8e-7aff-4646-a4cc-88ff8af16231",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pythonguides.com/remove-multiple-elements-from-a-list-in-python/\n",
    "#remove the stats columns from the list of columns, so this list can be passed to drop_duplicates\n",
    "cols_to_remove = ['stats.downloads','stats.unique_downloads','stats.views','stats.unique_views','stats.version_downloads','stats.version_unique_downloads','stats.version_unique_views','stats.version_views']\n",
    "\n",
    "zenodo_df_columns_filtered = [item for item in zenodo_df_columns if item not in cols_to_remove]\n",
    "print(zenodo_df_columns_filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1de12-b707-4414-bce7-fb07697a4da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the duplicate rows, using all columns except the stats ones to determine what's a dupe\n",
    "zenodo_df.loc[zenodo_df.astype(str).duplicated(subset=zenodo_df_columns_filtered,keep=False)].sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d987daed-383b-4705-aa7b-6cf93f5bdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_deduped = zenodo_df.loc[zenodo_df.astype(str).drop_duplicates(subset=zenodo_df_columns_filtered).index].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd0ae8-6888-493b-899d-171223919abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_deduped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f51b4-3d3e-43a2-8b25-05d31dcd1037",
   "metadata": {},
   "source": [
    "### Export lists for zenodo_get downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55680287-9c83-440c-8bdb-0222e1a961fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entire list of record ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e19bf8-58be-4bbc-86b1-845d694b02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample of 20 record ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809fa031-2fce-44fb-b683-cba7718781cb",
   "metadata": {},
   "source": [
    "### Add columns used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3284ad1e-5cdc-45d1-97e6-ff9ca79ac731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, export the publication dates to a CSV so they can be examined in OpenRefine and issues like whitespace or non-compliant ETDF dates found.\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_pub_dates = zenodo_df_deduped[['id','metadata.publication_date']]\n",
    "zenodo_pub_dates.to_csv(f'zenodo_pub_dates_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a64a6-cad9-4b0a-8211-e1ad20b85d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#then, fix and replace any dates that have issues.\n",
    "#two records were found to have issues with dates: 14215531 and 14030741\n",
    "#round 2 zenodo_df['metadata.publication_date'] = zenodo_df['metadata.publication_date'].str.strip().replace('02_08_2024','2024-08-02')\n",
    "zenodo_df_deduped['metadata.publication_date'] = zenodo_df_deduped['metadata.publication_date'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815bb4c-ad45-4280-b636-7b44cef6c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the records that had date issues before to make sure they are fixed: 13169677,14030741, 14215531\n",
    "zenodo_df_deduped.loc[zenodo_df_deduped['id'] == 14030741]['metadata.publication_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062ab4c0-9843-4fe8-9455-64ee64b8b20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the earliest publication year by using the EDTF library\n",
    "zenodo_df_deduped['earliest_pub_year'] = zenodo_df_deduped['metadata.publication_date'].apply(lambda x: parseable_date(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b5694b-1519-474e-a3e3-7e2675b79d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the date created column to a datetime format\n",
    "zenodo_df_deduped['created'] = pd.to_datetime(zenodo_df_deduped['created'], format='ISO8601')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01a364-0c23-4613-aee2-6c423c8dbc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a column for the year the record was created.\n",
    "zenodo_df_deduped['year_created']=pd.DatetimeIndex(zenodo_df_deduped['created']).year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b726e6-84cf-419c-8d57-950c930456d4",
   "metadata": {},
   "source": [
    "## Create dataframes for files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199a99ed-f1f6-4b82-8acb-97e07f022166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use json_normalize to create dataframes. each record represents a file from the metadata record.\n",
    "#https://stackoverflow.com/questions/52085169/valueerror-conflicting-metadata-name-name-need-distinguishing-prefix-in-pandas\n",
    "#since there are two JSON fields with key 'id', need to distinguish them using record_prefix\n",
    "zenodo_files_df = pd.json_normalize(zenodo_dict, record_path=[['files']],\n",
    "                                       meta=['id'], record_prefix='file'\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54adfb27-0a7e-4551-b413-b4fbd23fae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a7118c-c7ff-4230-92e5-4c770d125b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check for duplicates\n",
    "zenodo_files_df[zenodo_files_df.duplicated(keep=False)].sort_values('filekey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6b8463-555f-40b9-9580-9e5b5b05e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df[zenodo_files_df.duplicated(subset='fileid', keep=False)].sort_values('filekey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b63605-a01b-4309-ba98-a010df804bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped = zenodo_files_df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d88245-5583-45ea-b264-bf6b5f346336",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e350e018-820e-4c44-b8e0-25e380635e9f",
   "metadata": {},
   "source": [
    "## Drop the records did not download\n",
    "drop the records that contain files that couldn't be downloaded, because of a change in record status, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7281485-3789-48c2-a81f-a1e2aa8d61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for now, create copies for testing purposes\n",
    "zenodo_df_testcopy = zenodo_df.copy()\n",
    "zenodo_files_df_testcopy = zenodo_files_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c54366-0767-4ded-9077-40833770330e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inventory dataframe\n",
    "#https://www.geeksforgeeks.org/python-pandas-series-from_csv/\n",
    "file_inventory_df = pd.read_csv('file_inventory_2025-06-26_02-38_PM.csv')\n",
    "file_inventory_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5644e719-8fa8-4cf4-b233-d3aa25f30ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory_df = file_inventory_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8127592-ee66-43e9-b77d-f51eb1eab2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here want to get just a list of the recordids aka subdirectory_1, so need to g\n",
    "file_inventory_recordids = file_inventory_df['Subdirectory_Level_1'].unique()\n",
    "file_inventory_recordids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f20e21-2dbe-4896-8a41-9122c4645a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/50449088/check-if-value-from-one-dataframe-exists-in-another-dataframe\n",
    "#https://www.askpython.com/python-modules/pandas/pandas-isin\n",
    "#https://codemax.app/snippet/checking-if-elements-in-an-array-exist-in-a-pandas-dataframe-in-python/\n",
    "\n",
    "#Df1.assign(InDf2=Df1.name.isin(Df2.IDs).astype(int))\n",
    "\n",
    "zenodo_df_testcopy = zenodo_df_testcopy.assign(in_file_inventory=zenodo_df_testcopy['id'].isin(file_inventory_recordids))\n",
    "# fileinventory_record_filter = zenodo_df_testcopy['id'].isin(file_inventory_recordids)\n",
    "# zenodo_df_testcopy[fileinventory_record_filter]\n",
    "\n",
    "#zenodo_df_testcopy['in_file_inventory']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5620d84-3e5b-4d2c-8d46-89ca2c6b1311",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_testcopy = zenodo_df_testcopy.loc[zenodo_df_testcopy['in_file_inventory']==True]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887084e0-4521-44de-a1d9-731bbfe9ef60",
   "metadata": {},
   "source": [
    "## Analysis at the record level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3476ab-99fc-4eb1-b020-f17ce0afca51",
   "metadata": {},
   "source": [
    "### Record years plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5537f05f-f456-4df0-b360-44e0dd202397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of records across years\n",
    "# need to plot this in a more interesting way and ensure x axis marks properly show years\n",
    "# https://stackoverflow.com/questions/45108455/graphing-number-of-rows-over-time-in-pandas\n",
    "record_created_years_graph = zenodo_df_deduped.groupby('year_created').size().plot(kind='bar', color='purple', ylabel='Number of records', xlabel='Year record created', grid=False)\n",
    "#annotate bars\n",
    "record_created_years_graph.bar_label(record_created_years_graph.containers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de41f96-ad7e-4e7a-bc49-6e6def34ac45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of records across years\n",
    "# need to plot this in a more interesting way and ensure x axis marks properly show years\n",
    "record_published_years_graph = zenodo_df_deduped.groupby('earliest_pub_year').size().plot(kind='bar', color='maroon', ylabel='Number of records', xlabel='Publication year (earliest)', grid=False, figsize=(10,12))\n",
    "record_published_years_graph.bar_label(record_published_years_graph.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac952ac-1b56-4543-9f13-49a443d890c4",
   "metadata": {},
   "source": [
    "### Related identifiers analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9918008-85c5-4703-88fc-6e73510877ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of records related to some other research entity (deposit, article, etc) in metadata.related_identifiers\n",
    "zenodo_related_identifiers = zenodo_df_deduped[['id','metadata.related_identifiers']].dropna().rename({\"metadata.related_identifiers\": \"related_identifiers\"}, axis=\"columns\")\n",
    "zenodo_related_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b795375b-4a53-45de-9e57-d6ecdbd12afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers = zenodo_related_identifiers.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f8af3-7edc-4d03-ac90-17af23a161f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e5ab2d-4501-44b8-a7b7-7f3442f4df0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the contents of a cell\n",
    "zenodo_related_identifiers['related_identifiers'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b76efc-3146-4a91-a2fa-70b88c54c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put each related identifier, which is a dictionary/JSON object, in its own row\n",
    "#https://www.geeksforgeeks.org/convert-list-like-column-elements-to-separate-rows-in-pandas/\n",
    "zenodo_related_identifiers_melt = zenodo_related_identifiers.related_identifiers.apply(pd.Series).merge(zenodo_related_identifiers, right_index = True, left_index = True).drop(['related_identifiers'], axis = 1).melt(id_vars = ['id'], value_name = 'related_identifiers').drop('variable', axis=1).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1345012a-aa03-47c6-8ad4-fcbb4c20cd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_melt = zenodo_related_identifiers_melt.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89636f6-41e7-410f-800d-0218ab8d2147",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e431e1de-5066-4014-9f0d-ed016fcd30a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63598604-2eb0-481c-bc7c-d343681dbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put each identifier element in its own column\n",
    "#https://datascientyst.com/normalize-json-dict-new-columns-pandas/\n",
    "#https://stackoverflow.com/questions/46391291/how-to-convert-json-data-inside-a-pandas-column-into-new-columns\n",
    "zenodo_relations = pd.json_normalize(zenodo_related_identifiers_melt['related_identifiers'])\n",
    "#.merge(zenodo_related_identifiers_melt['id'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce440bf0-a175-4035-8c4c-d8163168dcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca965d99-7c18-407a-b27e-6779730673f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_relations.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adb9a0a-49f5-4d20-8e21-c87aafbe2eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the original related identifiers dataframe with the one that puts each element in its own column\n",
    "zenodo_related_identifiers_all = pd.concat([zenodo_relations, zenodo_related_identifiers_melt['id']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b92172-e7e6-4b21-b793-6b1e1d5046d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa7ab12-2a92-4653-9e1c-a4cd84a76c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_sankey = zenodo_related_identifiers_all[['relation','scheme']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63623814-472d-4382-8bd8-0af5fe155c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_sankey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6b0dbc-7d78-4fe6-975f-10af51c265b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider consolidating relationships to be bidirectional\n",
    "zenodo_related_identifiers_sankey['relation_consolidated'] = zenodo_related_identifiers_sankey['relation'].replace({'isSupplementTo':'supplementary','isSupplementedBy':'supplementary','isDerivedFrom':'sourcing','isSourceOf':'sourcing','isContinuedBy':'continuation','continues':'continuation','isCitedBy':'citation','cites':'citation','references':'referencing','isReferencedBy':'referencing','isDescribedBy':'description','describes':'description','documents':'documentation','isDocumentedBy':'documentation','isCompiledBy':'compilation','compiles':'compilation','hasPart':'partitive','isPartOf':'partitive','isMetadataFor':'metadata','hasMetadata':'metadata','requires':'requirement','isRequiredBy':'requirement','isVersionOf':'versioning','hasVersion':'versioning','isPreviousVersionOf':'superceding','isNewVersionOf':'superceding','obsoletes':'obsolesence','isObsoletedBy':'obsolesence','isReviewedBy':'reviewing','reviews':'reviewing'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eb60ff-8ca1-43a8-9f1a-93841a4edb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statology.org/pandas-groupby-to-dataframe/\n",
    "zenodo_related_identifiers_sankey_count = zenodo_related_identifiers_sankey.groupby(['relation_consolidated','scheme']).value_counts().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cee4d-bbb7-445d-81b9-dbc4e8575363",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_sankey_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63c8fb-1e2a-4a9a-bfd0-a0e9d0afc779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used Gemini for sankey prep: https://gemini.google.com/app/596c5c70ccb22615\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# --- 3. SANKEY CHART PREPARATION: Generating Labels and Indices ---\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# 3A. Create the unique list of all nodes (LABELS) for the Sankey chart\n",
    "all_nodes = pd.concat([zenodo_related_identifiers_sankey_count['relation_consolidated'], zenodo_related_identifiers_sankey_count['scheme']]).unique()\n",
    "df_labels = pd.Series(all_nodes).rename('Sankey_Labels')\n",
    "\n",
    "# Create a mapping dictionary: {ID_string: index_number}\n",
    "label_map = {label: i for i, label in enumerate(all_nodes)}\n",
    "\n",
    "# 3B. Map Source and Target IDs to their corresponding indices (Source/Target Index Lists)\n",
    "df_source_indices = zenodo_related_identifiers_sankey_count['relation_consolidated'].map(label_map).rename('Source_Index')\n",
    "df_target_indices = zenodo_related_identifiers_sankey_count['scheme'].map(label_map).rename('Target_Index')\n",
    "\n",
    "# Output 4: List of Weights for each relationship (Plotly Values)\n",
    "df_weights_only = zenodo_related_identifiers_sankey_count['count'].reset_index(drop=True).rename('Weight_List')\n",
    "\n",
    "\n",
    "print(\"--- 3. SANKEY OUTPUT A: Unique List of All Labels (Nodes) ---\")\n",
    "print(\"This is the 'label' argument for your Plotly Sankey chart.\")\n",
    "print(df_labels)\n",
    "print(f\"\\nTotal unique nodes: {len(df_labels)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(\"--- 4. SANKEY OUTPUT B: Source Indices ---\")\n",
    "print(\"The 'source' argument for Plotly. Maps each source ID to its index in the Labels list.\")\n",
    "print(df_source_indices)\n",
    "print(f\"\\nType: {type(df_source_indices)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"--- 5. SANKEY OUTPUT C: Target Indices ---\")\n",
    "print(\"The 'target' argument for Plotly. Maps each target ID to its index in the Labels list.\")\n",
    "print(df_target_indices)\n",
    "print(f\"\\nType: {type(df_target_indices)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(\"--- 6. SANKEY OUTPUT D: Weights (Values) ---\")\n",
    "print(\"The 'value' argument for Plotly (frequency of the relationship).\")\n",
    "print(df_weights_only)\n",
    "print(f\"\\nType: {type(df_weights_only)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e972e3-5277-46bd-aaa7-505c17e339b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    arrangement=\"freeform\",\n",
    "    node = dict(\n",
    "      pad = 15,\n",
    "      thickness = 20,\n",
    "      line = dict(color = \"black\", width = 0.1),\n",
    "      label = df_labels,\n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "      source = df_source_indices, # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = df_target_indices,\n",
    "      value = df_weights_only\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Relations and Schemes\", font_size=10, autosize=False,\n",
    "    width=800,\n",
    "    height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0160367-5f2a-4bdb-b632-a8b9534c2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a sense of the number of different kinds of relationships present\n",
    "#https://www.statology.org/pandas-value_counts-sort/\n",
    "#zenodo_related_identifiers_all.groupby(['relation']).count().sort_values(by='identifier',ascending=False)\n",
    "zenodo_related_identifiers_all.groupby(['relation'])['relation'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81337a5-8543-4867-9876-392bdff6dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_related_identifiers_all.groupby(['relation'])['relation'].value_counts().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41fadb3-f0bd-4612-8dc4-f71be1fcfafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a sense of the identifier schemes in use\n",
    "#zenodo_related_identifiers_all.groupby(['scheme']).count().sort_values(by='identifier',ascending=False)\n",
    "zenodo_related_identifiers_all.groupby(['scheme'])['scheme'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0801a6c-1fdd-40e6-be93-b93cad0b7225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zenodo_related_identifiers_all.groupby(['id']).count().sort_values(by='identifier',ascending=False)\n",
    "#https://stackoverflow.com/questions/50824493/pandas-groupby-filter-on-count\n",
    "#how many records have 10 or more related identifiers associated?\n",
    "zenodo_related_identifiers_all.groupby(['id'])['id'].value_counts()[lambda x: x>=100].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b6159-a928-4e47-a201-ffed4d4a43d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers_all.groupby(['id']).count().plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c1034-78b4-453b-8008-e44e12a0373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the related identifiers in their own file so they can be looked at in OpenRefine\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_related_identifiers_all.to_csv(f'zenodo_related_identifiers_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3591f-fa73-422f-8cd5-c30c153523cb",
   "metadata": {},
   "source": [
    "### Keyword analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6fc44-4845-46ef-98b1-ffaf1df4a9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look into extracting and analyzing keywords to get at discipline\n",
    "zenodo_keywords_df = zenodo_df_deduped[['id','metadata.keywords']].dropna().explode('metadata.keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69091d1-a6ad-4b32-8f45-616e64f381ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_keywords_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714c68d7-1957-47ae-963b-cee9d65049ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_keywords_df.to_csv(f'zenodo_keywords_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b02b7-e2bb-4d00-8c12-b2e9b384637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_deduped['id','metadata.subjects']].dropna()\n",
    "#.dropna().explode('metadata.keywords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6aec0-3386-4f43-8c55-49c2ae0ec39f",
   "metadata": {},
   "source": [
    "## Add columns to the dataframes that will be used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a1ec3c-2cb9-4183-b6bb-eaf3dd3b58e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for filename length\n",
    "zenodo_files_df_deduped['filekey_len'] = zenodo_files_df_deduped['filekey'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251df78-ec3c-4a4d-8940-e12eaf3362cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column for the file extensions\n",
    "#https://kanoki.org/2019/11/12/how-to-use-regex-in-pandas/\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.extract.html\n",
    "zenodo_files_df_deduped['filetype'] = zenodo_files_df_deduped['filekey'].str.extract(r'(?:.*)(\\..+)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e30e9c6-d69e-416d-8202-54c27ba8638b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped['filetype'] = zenodo_files_df_deduped['filetype'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eecf967-2b7d-46ba-8927-4798860f75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for files that don't have a proper file extension\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filetype'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d6caa-6044-48d7-aa37-b51d9a28d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for those that don't have an extension, fill column with word 'none'\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filetype'].isna()==True, 'filetype'] = zenodo_files_df_deduped['filetype'].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e437b093-5517-436f-b84f-7723a253e95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filetype'] == 'none']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac1212-00e0-4b2c-98a5-cc67bd881c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for the filename but without extension\n",
    "zenodo_files_df_deduped['filename_noext'] = zenodo_files_df_deduped['filekey'].str.extract(r'(.*)(?:\\..+)$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ddabf8-4933-4e2d-8245-35815e0b7b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped['filename_noext']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616818a-742c-48b8-a322-04245ec81d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for the filenames that couldn't be parsed because there was no extension\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caf444e-ed92-4722-9e6b-b2cfa83d0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "#copy the filekey over to the filename with no extension column\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].isna()==True, 'filename_noext'] = zenodo_files_df_deduped['filekey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25535984-a022-4755-b39b-93546cc69bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#double check that the copying worked\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].isna()==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9219db-d822-48fc-90a3-ce1dfaf8e702",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column for filename_noext length\n",
    "zenodo_files_df_deduped['filename_noext_len'] = zenodo_files_df_deduped['filename_noext'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a728b-b5f5-4055-afa4-f44b6dcb5edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns to dataframe that convert the file size in bytes to MB and GB respectively\n",
    "zenodo_files_df_deduped['filesize_mb'] = zenodo_files_df_deduped['filesize'].apply(lambda x: format_bytes(x, 'MB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e54f4a-5b05-4230-984d-2ee7d5aa2f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped['filesize_gb'] = zenodo_files_df_deduped['filesize'].apply(lambda x: format_bytes(x, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b291d6-b93a-4f33-a353-fdb7e6c99230",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e3899-34dc-4d5f-8356-ac9835ad2357",
   "metadata": {},
   "source": [
    "## Create a dataframe of just the spreadsheet files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b8dfbf-3c46-4622-aab1-c549562b8f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a list of spreadsheet file extensions\n",
    "spreadsheet_filetypes = ['.csv','.tsv','.xls','.xlsb','.xlsx','.xltx','.ods','.ots','.xlsm','.xltm','.xltx','.ogw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c6450a-ab56-43c2-935c-43adc3d33073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#https://stackoverflow.com/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql\n",
    "zenodo_spreadsheet_files_df = zenodo_files_df_deduped.query('filetype in @spreadsheet_filetypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9280a713-3ea2-410c-a701-801e2458c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff19ca2-f668-442d-9fd4-880e6f8d60a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df = zenodo_spreadsheet_files_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b99387-08ec-4944-b971-460f591f9dbb",
   "metadata": {},
   "source": [
    "### Check the file inventory against the list of spreadsheet files to make sure all downloaded OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb44242-547c-4457-bf74-61445b1cdb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to compare both the id and the filename columns in both dataframes to find out which ones from file_inventory_df are NOT in zenodo_files_df\n",
    "#https://stackoverflow.com/questions/48647534/find-difference-between-two-data-frames\n",
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.compare.html\n",
    "#need to move this after creating the dataframe of just the spreadsheet files.\n",
    "zenodo_spreadsheet_files_df_testcopy = zenodo_spreadsheet_files_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d2034-5716-45f1-a237-b202481586ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_testcopy_compare = zenodo_spreadsheet_files_df_testcopy[['id','filekey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479de5c5-41e2-4fb7-b04a-597456112c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory_df_compare = file_inventory_df[['Subdirectory_Level_1','File']].set_axis(['id', 'filekey'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9e562d-bff7-498c-865a-a683d9cb0e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory_df_compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a02562-2c32-4707-b355-21da76e063a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/48647534/find-difference-between-two-data-frames\n",
    "#df1.merge(df2,indicator = True, how='left').loc[lambda x : x['_merge']!='both']\n",
    "zenodo_spreadsheet_files_downloaded = zenodo_spreadsheet_files_df_testcopy_compare.merge(file_inventory_df_compare,indicator=True,how='left').loc[lambda x : x['_merge']=='both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55f3ed2-78f3-427c-a950-82a253db8da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3d895b-e719-46a3-ad0d-e637b2fd77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/48864923/select-certain-rows-by-index-of-another-dataframe\n",
    "#df[df.index.isin(df1.index)]\n",
    "zenodo_spreadsheet_files_df_testcopy_check = zenodo_spreadsheet_files_df_testcopy[zenodo_spreadsheet_files_df.index.isin(zenodo_spreadsheet_files_downloaded.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042ad365-f30e-4664-8837-f750c8f98a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_testcopy_check.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c340e7-3367-4030-a3b7-e75cec4e5110",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_downloaded.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc31904-ad75-43c8-b9f5-c7a3709271cb",
   "metadata": {},
   "source": [
    "## Analysis of size of the corpus: counts and file size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce560b6b-1012-483b-a083-9f578193dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for files that are over 50 GB\n",
    "zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filesize_gb'] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3db32da-a415-4ae1-98c7-97397ecea1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some stats about the different file types. reveals that there are some poorly formed file names without proper extensions.\n",
    "zenodo_files_df_deduped.groupby(['filetype']).agg({'filesize_mb': ['mean', 'min', 'max', 'median', 'count','sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd3bc12-ec5b-4656-80e5-98e6e776e10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the spreadsheet files dataframe\n",
    "#275424\n",
    "zenodo_spreadsheet_files_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f55ae3-3558-4044-ab04-8dbf91b4bdc3",
   "metadata": {},
   "source": [
    "### Get the total filesize of all spreadsheets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7d7b76-4cd3-4066-ac6d-3025ed8a25a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41286569/get-total-of-pandas-column\n",
    "spreadsheet_filesize_total = zenodo_spreadsheet_files_df['filesize'].sum()\n",
    "print(spreadsheet_filesize_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad950b55-3287-4aa9-a0ea-d1393afce099",
   "metadata": {},
   "outputs": [],
   "source": [
    "#format the total filesize of all spreadsheets in TB\n",
    "format_bytes(spreadsheet_filesize_total, 'TB', SI=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3f2ec4-e117-4a18-960d-8998ea0dbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total number of spreadsheet files\n",
    "#https://stackoverflow.com/questions/41286569/get-total-of-pandas-column\n",
    "spreadsheet_files_count = len(zenodo_spreadsheet_files_df.index)\n",
    "print(spreadsheet_files_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36a91ce-0de4-4ff5-9687-deb326080078",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5eb01-d10e-42bf-87f1-d1f526c61a45",
   "metadata": {},
   "source": [
    "### Get some basic stats about the spreadsheet files broken out by filetype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfccf6f-6b60-40cb-bd01-36431198a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some basic stats about the spreadsheet files.\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype']).agg({'filesize': ['mean', 'min', 'max', 'median', 'count','sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ab3ee-d107-4639-8647-65605624af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some basic stats about the spreadsheet files, in GB.\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype']).agg({'filesize_gb': ['mean', 'min', 'max', 'median', 'count','sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb47a191-401d-48e8-ba6b-c6d60e8be7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get some basic stats about the spreadsheet files, in MB.\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype']).agg({'filesize_mb': ['mean', 'min', 'max', 'median', 'count','sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575dcc4-cfb8-41da-b85d-139e7a361d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the total size of all files by filetype\n",
    "#https://dnmtechs.com/calculating-percentage-of-total-with-pandas-groupby-in-python-3/\n",
    "zenodo_spreadsheet_files_size_grouped = zenodo_spreadsheet_files_df.groupby(['filetype']).agg({'filesize': ['sum']})\n",
    "zenodo_spreadsheet_files_size_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9115fb-58c2-4716-b65b-f9ef165d2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the total size in GB of all files by filetype\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype']).agg({'filesize_gb': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252b7ced-6c51-4093-a7fb-f44d6ea016e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the total count of all files by filetype\n",
    "zenodo_spreadsheet_files_count_grouped = zenodo_spreadsheet_files_df.groupby('filetype').agg({'id':'count'}).sort_values(by='id', ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701dbedb-ae07-46e1-91bc-7bb858bf6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_count_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37be60e-63e4-4a17-8105-fe22f879c85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.groupby('filetype')['filetype'].value_counts().sort_values().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a418b6c-5cf3-4d2b-80b3-e90551e3f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_count_grouped.plot(kind='pie', subplots=True, figsize=(8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135af295-283b-4cc4-8343-5e17f1b32850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the sizes of each filetype as percentages\n",
    "zenodo_spreadsheet_files_size_grouped.transform(lambda x: (x / spreadsheet_filesize_total) * 100)\n",
    "#.groupby(level=0).apply(lambda x:100 * x / float(x.sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62bb40-031f-48bb-b800-06075560db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the count of each filetype as percentages\n",
    "zenodo_spreadsheet_files_count_grouped.transform(lambda x: (x / spreadsheet_files_count) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64307ab-1bb1-4048-9d79-253be1937dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate just the Excel files of various types\n",
    "zenodo_spreadsheet_files_count_grouped.loc[['.xlsx','.xls','.xlsm','.xlsb','.xltx','.xltm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf8a7ef-7ab0-42f9-8dc7-cd36331779f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total number of all the Excel files of various types\n",
    "zenodo_spreadsheet_files_count_grouped.loc[['.xlsx','.xls','.xlsm','.xlsb','.xltx','.xltm']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2929e5-f672-4de3-8adb-d7884c2940ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total percentage of all the Excel files of various types\n",
    "zenodo_spreadsheet_files_count_grouped.loc[['.xlsx','.xls','.xlsm','.xlsb','.xltx','.xltm']].sum().transform(lambda x: (x / spreadsheet_files_count) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f20227a-3104-43f0-9539-5559175dc9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total number of all tabular files\n",
    "zenodo_spreadsheet_files_count_grouped.loc[['.csv','.tsv']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3478eae1-ae98-4142-bd05-91ea56b9548c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the total percentage of all tabular files\n",
    "zenodo_spreadsheet_files_count_grouped.loc[['.csv','.tsv']].sum().transform(lambda x: (x / spreadsheet_files_count) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45527f6-f0d6-4bd5-8ed9-fe436fbd11e6",
   "metadata": {},
   "source": [
    "### Various plots of file size and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a7565a-4d82-4f8f-966f-21e0ca142d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(zenodo_spreadsheet_files_df[zenodo_spreadsheet_files_df['filetype']=='.ods'].filesize_gb, bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8910e48e-98e2-4ddd-80df-224351379cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(zenodo_spreadsheet_files_df.filesize_gb, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572dc6d9-1875-4962-ab7f-9a2305ad05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_groups = zenodo_spreadsheet_files_df.groupby('filetype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0a464-5efc-4550-94a2-82dfadeb5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.groupby('filetype')['filesize_gb'].plot(legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45398dce-71e6-47c1-b7fb-6517c19a562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_groups.get_group('.csv')['filesize_gb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a7d5eb-a404-4f30-b1d6-76755e26a864",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11,1,figsize=(25,30), squeeze=True)\n",
    "\n",
    "ax[0].hist(zenodo_spreadsheet_files_groups.get_group('.csv')['filesize_gb'], bins=50)\n",
    "ax[0].set_title('CSV size in GB')\n",
    "ax[1].hist(zenodo_spreadsheet_files_groups.get_group('.tsv')['filesize_gb'], bins=50)\n",
    "ax[1].set_title('TSV size in GB')\n",
    "ax[2].hist(zenodo_spreadsheet_files_groups.get_group('.xlsx')['filesize_gb'], bins=50)\n",
    "ax[2].set_title('XLSX size in GB')\n",
    "ax[3].hist(zenodo_spreadsheet_files_groups.get_group('.xls')['filesize_gb'], bins=50)\n",
    "ax[3].set_title('XLS size in GB')\n",
    "ax[4].hist(zenodo_spreadsheet_files_groups.get_group('.xlsb')['filesize_gb'], bins=50)\n",
    "ax[4].set_title('XLSB size in GB')\n",
    "ax[5].hist(zenodo_spreadsheet_files_groups.get_group('.xltx')['filesize_gb'], bins=50)\n",
    "ax[5].set_title('XLTX size in GB')\n",
    "ax[6].hist(zenodo_spreadsheet_files_groups.get_group('.xlsm')['filesize_gb'], bins=50)\n",
    "ax[6].set_title('XLSM size in GB')\n",
    "ax[7].hist(zenodo_spreadsheet_files_groups.get_group('.xltm')['filesize_gb'], bins=50)\n",
    "ax[7].set_title('XLTM size in GB')\n",
    "ax[8].hist(zenodo_spreadsheet_files_groups.get_group('.ods')['filesize_gb'], bins=50)\n",
    "ax[8].set_title('ODS size in GB')\n",
    "ax[9].hist(zenodo_spreadsheet_files_groups.get_group('.ots')['filesize_gb'], bins=50)\n",
    "ax[9].set_title('OTS size in GB')\n",
    "ax[10].hist(zenodo_spreadsheet_files_groups.get_group('.ogw')['filesize_gb'], bins=50)\n",
    "ax[10].set_title('OGW size in GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d98d630-b4f9-44ad-b6b3-6734133e9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(11,1,figsize=(25,30), squeeze=True)\n",
    "\n",
    "ax[0].hist(zenodo_spreadsheet_files_groups.get_group('.csv')['filesize_mb'], bins=50)\n",
    "ax[0].set_title('CSV size in MB')\n",
    "ax[1].hist(zenodo_spreadsheet_files_groups.get_group('.tsv')['filesize_mb'], bins=50)\n",
    "ax[1].set_title('TSV size in MB')\n",
    "ax[2].hist(zenodo_spreadsheet_files_groups.get_group('.xlsx')['filesize_mb'], bins=50)\n",
    "ax[2].set_title('XLSX size in MB')\n",
    "ax[3].hist(zenodo_spreadsheet_files_groups.get_group('.xls')['filesize_mb'], bins=50)\n",
    "ax[3].set_title('XLS size in MB')\n",
    "ax[4].hist(zenodo_spreadsheet_files_groups.get_group('.xlsb')['filesize_mb'], bins=50)\n",
    "ax[4].set_title('XLSB size in MB')\n",
    "ax[5].hist(zenodo_spreadsheet_files_groups.get_group('.xltx')['filesize_mb'], bins=50)\n",
    "ax[5].set_title('XLTX size in MB')\n",
    "ax[6].hist(zenodo_spreadsheet_files_groups.get_group('.xlsm')['filesize_mb'], bins=50)\n",
    "ax[6].set_title('XLSM size in MB')\n",
    "ax[7].hist(zenodo_spreadsheet_files_groups.get_group('.xltm')['filesize_mb'], bins=50)\n",
    "ax[7].set_title('XLTM size in MB')\n",
    "ax[8].hist(zenodo_spreadsheet_files_groups.get_group('.ods')['filesize_mb'], bins=50)\n",
    "ax[8].set_title('ODS size in MB')\n",
    "ax[9].hist(zenodo_spreadsheet_files_groups.get_group('.ots')['filesize_mb'], bins=50)\n",
    "ax[9].set_title('OTS size in MB')\n",
    "ax[10].hist(zenodo_spreadsheet_files_groups.get_group('.ogw')['filesize_mb'], bins=50)\n",
    "ax[10].set_title('OGW size in MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2173c77-8997-42de-b183-566f4379029c",
   "metadata": {},
   "source": [
    "## Analysis of file names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06734db2-4392-423f-8af1-9698a53d43fd",
   "metadata": {},
   "source": [
    "### Files were deposited in multiple formats\n",
    "determined by looking for the same file name with different extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98645e-b66f-4dc2-843d-90c17331c2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e4aaf-fe5e-4968-8bd3-c4feaf96237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the dataframe by id, filename, and filetype\n",
    "zenodo_files_df_sorted = zenodo_files_df_deduped.sort_values(by=['id','filename_noext','filetype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a25a00c-1ebb-4cbd-a277-698cdbb0bf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf73e4-269d-4f7d-8646-e1cb51cacaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a filename with no extension has multiple filetypes, concatenate those in the filetype column\n",
    "#https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby\n",
    "zenodo_files_df_sorted.groupby(['id','filename_noext'], sort=False).agg({'filename_noext':'count', 'filetype': ', '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9534f17f-2d00-4beb-b0a7-d40857efd392",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if a filename with no extension has multiple filetypes, concatenate those in the filetype column\n",
    "#now put that groupby in its own dataframe\n",
    "#https://stackoverflow.com/questions/27298178/concatenate-strings-from-several-rows-using-pandas-groupby\n",
    "filename_counts = zenodo_files_df_sorted.groupby(['id','filename_noext'], sort=False).agg({'filename_noext':'count', 'filetype': ', '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa16128-650e-4bdd-8612-9a1deea312f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040c436c-56fc-4be6-8893-79aa4289b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a6b2c-d618-44a6-8e2e-09389f9444e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset some indexes and column names\n",
    "filename_counts.index.name = None\n",
    "filename_counts.columns=['counts', 'filetype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfd94b0-9d67-4e85-bbab-1200d56296bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_counts = filename_counts.rename_axis(['id','filename_noext']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caf743d-12f7-46bb-b42f-75fdc80096a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4994d5fc-0207-47e0-ba98-aa12f05f8278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from the dataframe that counts filenames with no extensions, find the ones greater than 1\n",
    "filename_duplicates = filename_counts.loc[filename_counts['counts']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e51c9b-7172-4e2f-adc6-cbd5fb3fc650",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c8ac1e-6916-4eb2-a7b3-0863b3f8ed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the dataframe of duplicate filenames so this can be looked at in OpenRefine\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "filename_duplicates.to_csv(f'filename_duplicates_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2b4328-6eee-456e-9bb4-2b593fd274cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now count how many instances of duplicate files occur per record\n",
    "filename_duplicates_counts = filename_duplicates.groupby(['id']).agg({'counts':'count'}).sort_values(by='counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f3c526-d687-4dde-9560-f918d95d390d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26129204-d1e4-4034-b4f1-2a08d55eafb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates.loc[filename_duplicates['id']==14583147]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fa42a6-121f-4cf7-96ca-c71e11e5c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_counts.loc[filename_duplicates_counts['counts']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f604b7ca-3a35-4c48-8e18-a175a23e17d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out how many records have multiple instances of duplicate filenames that are also spreadsheets\n",
    "filename_duplicates_spreadsheets = filename_duplicates.loc[filename_duplicates['filetype'].str.contains(r'\\.csv|\\.tsv|\\.xls[xbm]?|\\.xlt[xm]?|\\.ods|\\.ots|\\.ogw', regex=True, case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702a561-0d1e-42c6-a88f-f790f17b5f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fe409f-e3d6-4472-befc-0d88a2e5b85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_spreadsheets_filetype_counts = filename_duplicates_spreadsheets.groupby('filetype',).count().sort_values(by='counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0000a55e-63dc-4160-85af-93334eb3fa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_spreadsheets_filetype_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d5b1c-4b97-4938-8e93-b2bd79b3744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "filename_duplicates_spreadsheets.to_csv(f'filename_duplicates_spreadsheets_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7791c2-e2fd-41c9-b21d-2d8d589551c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename_duplicates_spreadsheets['filetype'] contains two or more items from spreadsheet_filetypes list\n",
    "#used Google Gemini for help; it suggested str.count\n",
    "filename_duplicates_spreadsheets_multispreadsheets = filename_duplicates_spreadsheets[filename_duplicates_spreadsheets['filetype'].str.count(r'\\.csv|\\.tsv|\\.xls[xbm]?|\\.xlt[xm]?|\\.ods|\\.ots|\\.ogw')>= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c8dd7-cd88-49e9-ad82-a1f3c46d5d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_duplicates_spreadsheets_multispreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d863b68-f879-43a9-bf75-22206d28b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what are the combinations of spreadsheet filetypes? how many represent the good practice of open version of a proprietary format?\n",
    "filename_duplicates_spreadsheets_multispreadsheets.groupby('filetype')['filetype'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ad251-8dc4-47ee-9469-3c025fe5ef66",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "filename_duplicates_spreadsheets_multispreadsheets.to_csv(f'filename_duplicates_spreadsheets_multispreadsheets_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1812e-f79d-4130-b397-348e9f84af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gemini https://gemini.google.com/app/88f42355ff50fbba\n",
    "# create a df with source and target so can do this: https://frankcorso.me/chord-diagram-python-visualize-connections.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb705b97-d8bd-4342-b2ae-27b2e7d9137c",
   "metadata": {},
   "source": [
    "### Chord diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5ff5bc-7ded-415c-be4d-d74320d06fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gemini https://gemini.google.com/app/88f42355ff50fbba and Sankey prep gemini response\n",
    "from itertools import combinations\n",
    "\n",
    "multiple_spreadsheets_chord = filename_duplicates_spreadsheets_multispreadsheets.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e80df9f-44bc-4a96-a9c9-7515a6053231",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a5323a-fa6c-4a3e-97fb-5eeaca305094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Preparation Steps ---\n",
    "# 1. Split the 'filetype' string into a clean list of extensions\n",
    "multiple_spreadsheets_chord['Extensions_List'] = multiple_spreadsheets_chord['filetype'].str.split(',').apply(\n",
    "    lambda x: [item.strip() for item in x if item.strip()]\n",
    ")\n",
    "multiple_spreadsheets_chord['Extensions_List']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83102914-c0df-4ebe-a92a-17acc17d53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Generate all unique combinations (pairs) for each row's list\n",
    "#    combinations(list, 2) ensures pairs are not duplicated within a list (e.g., no (.ods, .ods))\n",
    "multiple_spreadsheets_chord['Combinations'] = multiple_spreadsheets_chord['Extensions_List'].apply(lambda x: list(combinations(x, 2)))\n",
    "multiple_spreadsheets_chord['Combinations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a989636-fba7-48f0-b05c-fde428bae403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Explode the 'Combinations' column to create one row per pair\n",
    "multiple_spreadsheets_chord_exploded = multiple_spreadsheets_chord[['id', 'Combinations']].explode('Combinations', ignore_index=True)\n",
    "multiple_spreadsheets_chord_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1e33ef-adc4-4be6-9cc2-8a7f7fcd6c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extract the Source and Target from the tuple pairs\n",
    "multiple_spreadsheets_chord_exploded[['Source_Extension', 'Target_Extension']] = pd.DataFrame(\n",
    "    multiple_spreadsheets_chord_exploded['Combinations'].tolist(),\n",
    "    index=multiple_spreadsheets_chord_exploded.index\n",
    ")\n",
    "multiple_spreadsheets_chord_exploded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307cb64-01be-4419-bbfe-ede1bc27853a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Create a globally unique key for counting (e.g., sorted tuple)\n",
    "#    This treats (.ods, .xlsx) and (.xlsx, .ods) as the same pair.\n",
    "multiple_spreadsheets_chord_exploded['Unique_Pair_Key'] = multiple_spreadsheets_chord_exploded.apply(\n",
    "    lambda row: tuple(sorted([row['Source_Extension'], row['Target_Extension']])),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e832909b-0e6a-4f92-987d-97bee65ee4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b805f909-f7ab-475d-a571-fb5baa174f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Expanded Table ---\n",
    "multiple_spreadsheets_chord_expanded_final = multiple_spreadsheets_chord_exploded.drop(columns=['Combinations']).reset_index(drop=True)\n",
    "\n",
    "print(\"--- Expanded DataFrame with Record ID ---\")\n",
    "print(multiple_spreadsheets_chord_expanded_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c1e6c4-f8fe-41ab-8571-b1cdb52982d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple_spreadsheets_chord_exploded_counts = multiple_spreadsheets_chord_exploded.groupby('Unique_Pair_Key')['Unique_Pair_Key'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15705b9e-1b5f-4775-9e3f-6432fab470ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts = multiple_spreadsheets_chord_exploded.groupby('Unique_Pair_Key', sort=False).agg({'Unique_Pair_Key':'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945c4ac-105b-4293-8a09-f254f27a888c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347d7de5-79b2-4ac3-9577-2ba3047b7f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset some indexes and column names\n",
    "multiple_spreadsheets_chord_exploded_counts.index.name = None\n",
    "multiple_spreadsheets_chord_exploded_counts.columns=['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bf6f0-41fc-4f0f-98cd-7546bb201ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c53617b-f25d-4f2a-9788-2dd6d4498f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed = multiple_spreadsheets_chord_exploded_counts.rename_axis(['Unique_Pair_Key']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296d563e-a31f-4f46-b38a-ba5b03d4f17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0299cdb-3764-4980-9d5d-7449cf53ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Extract the Source and Target from the tuple pairs\n",
    "multiple_spreadsheets_chord_exploded_counts_reindexed[['Source_Extension', 'Target_Extension']] = pd.DataFrame(\n",
    "    multiple_spreadsheets_chord_exploded_counts_reindexed['Unique_Pair_Key'].tolist(),\n",
    "    index=multiple_spreadsheets_chord_exploded_counts_reindexed.index\n",
    ")\n",
    "multiple_spreadsheets_chord_exploded_counts_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab51eb3-8627-41f3-8c7e-55fec957c789",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(multiple_spreadsheets_chord_exploded_counts_reindexed['Unique_Pair_Key'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018268af-7290-4e9b-b3b7-d0d2f731535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed['Target_Extension']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a110abe-35ff-4802-a165-6f399550c532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3A. Create the unique list of all nodes (LABELS) for the Chord chart\n",
    "# multiple_spreadsheets_chord_exploded_counts_reindexed_all_nodes = pd.concat([multiple_spreadsheets_chord_exploded_counts_reindexed['Source_Extension'], multiple_spreadsheets_chord_exploded_counts_reindexed['Target_Extension']]).unique()\n",
    "# multiple_spreadsheets_chord_exploded_counts_reindexed_labels = pd.Series(multiple_spreadsheets_chord_exploded_counts_reindexed_all_nodes).rename('Chord_Labels')\n",
    "\n",
    "# # Create a mapping dictionary: {ID_string: index_number}\n",
    "# multiple_spreadsheets_chord_exploded_counts_reindexed_label_map = {label: i for i, label in enumerate(multiple_spreadsheets_chord_exploded_counts_reindexed_all_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a9e08a-de2a-4814-85b5-d18472331067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3A. Create the unique list of all nodes (LABELS) for the Sankey chart\n",
    "all_nodes = pd.concat([multiple_spreadsheets_chord_exploded_counts_reindexed['Source_Extension'], multiple_spreadsheets_chord_exploded_counts_reindexed['Target_Extension']]).unique()\n",
    "all_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1444cf3b-d68b-48c4-b7be-c7ba9e20097a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels = pd.Series(all_nodes).rename('Chord_Labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042ff39-0f6f-422a-9f08-08a7b657438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c65bcfb-dcbd-459c-bf20-eebdacb9b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary: {ID_string: index_number}\n",
    "label_map = {label: i for i, label in enumerate(all_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62a6a54-104a-4267-b554-8f447d8710de",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda83de1-7bce-4fb0-bae4-9272c923a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3B. Map Source and Target IDs to their corresponding indices (Source/Target Index Lists)\n",
    "multiple_spreadsheets_chord_exploded_counts_reindexed['Source_Index'] = multiple_spreadsheets_chord_exploded_counts_reindexed['Source_Extension'].map(label_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce4489b-9724-4ad2-b733-456febe76244",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b380ad-eaf1-49f6-acad-0c956e08b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed['Target_Index'] = multiple_spreadsheets_chord_exploded_counts_reindexed['Target_Extension'].map(label_map).rename('Target_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8088af-ec90-4c91-9519-ba585455cba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5999212b-9b62-4f98-b985-4bf08444671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed[['Unique_Pair_Key','counts']].loc[multiple_spreadsheets_chord_exploded_counts_reindexed['counts']>1].sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a794f-3851-4362-bffd-83d17afeff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_spreadsheets_chord_exploded_counts_reindexed.plot(kind='bar', color='purple', grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42ab2b0-d112-4a70-b3eb-7f53bdff0998",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df = multiple_spreadsheets_chord_exploded_counts_reindexed[['Source_Index','Target_Index','counts']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7031c901-ec1e-4ed7-86fc-925222663ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df_holo = connections_df.rename(columns={'Source_Index':'source','Target_Index':'target','counts':'value'}).sort_values(by='value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c3b80-8114-4807-983e-5c337f9f82f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_df_holo.sort_values(by='value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d20ed6-5fb2-4de2-8eff-6133b23be073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "from holoviews import opts, dim\n",
    "\n",
    "hv.extension('matplotlib')\n",
    "hv.output(fig='svg', size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5627144d-644e-4aa7-a1f0-2673691e2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Chord(connections_df_holo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b61373-18ba-4eba-818b-ae8f02c18322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_dataframe = pd.DataFrame(df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b98fac-c4a8-4fba-99d8-f2e172398cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28585b06-1041-43e9-b559-694ba8b3a600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8cfd41-9ca5-4d6b-8399-ec7603a56aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset some indexes and column names\n",
    "df_labels_dataframe.index.name = None\n",
    "df_labels_dataframe.columns=['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74cc39a-3fa0-4b86-a09c-b9aa52ea0a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b97262-6a48-49ce-9295-48bd29dc3190",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ds = hv.Dataset(df_labels_dataframe, 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7e7b03-f35b-44f3-b947-b67394b98d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542283f5-9564-4d6c-a84b-8de8518ddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hv.Chord((connections_df_holo, nodes_ds)).opts(opts.Chord(\n",
    "        cmap='Category20',\n",
    "        edge_color=dim('source').astype(str),\n",
    "        labels='label', # Make sure this matches the column name from nodes_df\n",
    "        node_color=dim('index').astype(str),\n",
    "        edge_linewidth=1,\n",
    "        node_size=25\n",
    "    )\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ca784b-32e4-4e48-90dc-67b55e439c0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4811d03d-fab5-48dc-aa3b-ac1073d259e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    arrangement = \"perpendicular\",\n",
    "    orientation=\"v\",\n",
    "    node = dict(\n",
    "      #pad = 15,\n",
    "      #thickness = 20,\n",
    "      line = dict(color = \"black\"),\n",
    "      label = df_labels_dataframe,\n",
    "        # x = [0.2, 0.1, 0.5, 0.7, 0.3, 0.5],\n",
    "        # y =  [0.7, 0.5, 0.2, 0.4, 0.2, 0.3],\n",
    "        align=\"justify\",\n",
    "        \n",
    "      color = \"blue\"\n",
    "    ),\n",
    "    link = dict(\n",
    "        #arrowlen=15,\n",
    "      source = connections_df_holo['source'], # indices correspond to labels, eg A1, A2, A1, B1, ...\n",
    "      target = connections_df_holo['target'],\n",
    "      value = connections_df_holo['value']\n",
    "  ))])\n",
    "\n",
    "fig.update_layout(title_text=\"Filetypes\", font_size=10, \n",
    " autosize=False,\n",
    "     width=800,\n",
    "    height=900\n",
    "                 )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd54b6f-53ab-400a-8d9a-aebb467daf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#used Gemini for sankey prep: https://gemini.google.com/app/596c5c70ccb22615\n",
    "\n",
    "# --------------------------------------------------------------------------------------\n",
    "# --- 3. SANKEY CHART PREPARATION: Generating Labels and Indices ---\n",
    "# --------------------------------------------------------------------------------------\n",
    "\n",
    "# 3A. Create the unique list of all nodes (LABELS) for the Sankey chart\n",
    "all_nodes = pd.concat([zenodo_related_identifiers_sankey_count['relation'], zenodo_related_identifiers_sankey_count['scheme']]).unique()\n",
    "df_labels = pd.Series(all_nodes).rename('Sankey_Labels')\n",
    "\n",
    "# Create a mapping dictionary: {ID_string: index_number}\n",
    "label_map = {label: i for i, label in enumerate(all_nodes)}\n",
    "\n",
    "# 3B. Map Source and Target IDs to their corresponding indices (Source/Target Index Lists)\n",
    "df_source_indices = zenodo_related_identifiers_sankey_count['relation'].map(label_map).rename('Source_Index')\n",
    "df_target_indices = zenodo_related_identifiers_sankey_count['scheme'].map(label_map).rename('Target_Index')\n",
    "\n",
    "# Output 4: List of Weights for each relationship (Plotly Values)\n",
    "df_weights_only = zenodo_related_identifiers_sankey_count['count'].reset_index(drop=True).rename('Weight_List')\n",
    "\n",
    "\n",
    "print(\"--- 3. SANKEY OUTPUT A: Unique List of All Labels (Nodes) ---\")\n",
    "print(\"This is the 'label' argument for your Plotly Sankey chart.\")\n",
    "print(df_labels)\n",
    "print(f\"\\nTotal unique nodes: {len(df_labels)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(\"--- 4. SANKEY OUTPUT B: Source Indices ---\")\n",
    "print(\"The 'source' argument for Plotly. Maps each source ID to its index in the Labels list.\")\n",
    "print(df_source_indices)\n",
    "print(f\"\\nType: {type(df_source_indices)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "\n",
    "print(\"--- 5. SANKEY OUTPUT C: Target Indices ---\")\n",
    "print(\"The 'target' argument for Plotly. Maps each target ID to its index in the Labels list.\")\n",
    "print(df_target_indices)\n",
    "print(f\"\\nType: {type(df_target_indices)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "print(\"--- 6. SANKEY OUTPUT D: Weights (Values) ---\")\n",
    "print(\"The 'value' argument for Plotly (frequency of the relationship).\")\n",
    "print(df_weights_only)\n",
    "print(f\"\\nType: {type(df_weights_only)}\\n\")\n",
    "print(\"-\" * 50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e759d-fa32-4c5f-b5d5-6ad71e2a819a",
   "metadata": {},
   "source": [
    "### Records containing more than one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5f92de-521e-4e1d-ae74-dd59645172af",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff33ff6-7eb1-46eb-b78a-fc4adcb2f934",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_files_df_deduped['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e42869-2a67-426a-b57d-670194789a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rather than looking at duplicate filenames, here we look for records that have more than one file attached\n",
    "zenodo_files_df_deduped.groupby(['id'])['filetype'].apply(','.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a423884-b75e-4f1b-a17c-28e9a66da873",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped.groupby(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d78267-7ebd-40a1-aa80-27400178cf74",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts = zenodo_files_df_deduped.groupby(['id']).agg({'filekey':'count', 'filetype': ', '.join}).sort_values(by='filekey', ascending=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7bdc97-d44e-4f60-8a53-434dacc0ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4ee87-a911-443e-956f-6422c6cacc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd6b86-31c4-4731-b828-29dec059eb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts.index.name = None\n",
    "zenodo_files_df_deduped_filecounts.columns=['counts', 'filetype']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fada37b2-5962-4deb-8702-08c911de81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924ab5a3-31ed-4782-bca5-0130794de33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts = zenodo_files_df_deduped_filecounts.rename_axis(['id']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7738663-c4de-40c0-9186-8e9465ebae64",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafb2792-82cc-454e-ae0e-ae03bade2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(zenodo_files_df_deduped_filecounts.counts, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576c1a26-90d2-42e6-8f9a-0965f3c996c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_files_df_deduped_filecounts.drop(['filetype','id'], axis=1).plot(kind='box',legend=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f229e9-3bef-45cb-954d-4f9ec47016e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files = zenodo_files_df_deduped_filecounts.loc[zenodo_files_df_deduped_filecounts['counts']==1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3dab4-3daf-4e1d-aceb-758847a72178",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15c6d7c-c082-4678-9fbe-6c934d61db84",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files.groupby('filetype').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13f4b0c-9ea1-4f89-9ec2-54b4afaa7a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_related_identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307963d3-d722-4442-90e5-08567a1f3a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0924d-d0b6-4ef4-9d85-66f962c6d81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files_related_identifiers = single_files.join(zenodo_related_identifiers.set_index('id'), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9dc4c-7abc-4330-b5d9-abe58c188550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/25050141/how-to-filter-in-nan-pandas\n",
    "single_files_related_identifiers[~single_files_related_identifiers['related_identifiers'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72bc6a9-ea8c-454e-833c-6c53b5176481",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_files_related_identifiers[single_files_related_identifiers['related_identifiers'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fb6fc-21ce-47b7-99f4-3b9c4ff873a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#based on the counts of how many files there are on a given record, now look for records with more than one file on them\n",
    "#used Google gemini to understand why I need to set as a copy\n",
    "multiple_files = zenodo_files_df_deduped_filecounts.loc[zenodo_files_df_deduped_filecounts['counts']>1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e4a03-730d-4074-94da-8a7672115760",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aefa17-188d-4be8-984d-9f44d455db55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random check of records with 4 files attached\n",
    "zenodo_files_df_deduped_filecounts.loc[zenodo_files_df_deduped_filecounts['counts']==4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1590a6e0-7d0b-42ff-b081-1c109ed9830b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot of records with multiple files attached\n",
    "multiple_files['counts'].plot(kind='hist', legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30478495-6632-4065-b055-4fb52d38169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9463be-5f02-4b2c-b230-b5da53c6c6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column that counts how many spreadsheet files there are on a record, making sure it's case insensitive\n",
    "multiple_files['spreadsheet_count'] = multiple_files['filetype'].str.count(r'(\\.csv|\\.tsv|\\.xls[xbm]?|\\.xlt[xm]?|\\.ods|\\.ots|\\.ogw)', re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fa6f17-1aff-4e97-9bdc-97cab67aff0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files = multiple_files.sort_values(by='spreadsheet_count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c8e56-6875-4503-8696-88c6c9e570b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ae0c42-e1db-4485-b875-129addecd63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files.sort_values(by='counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e979cbe-cf5c-4b46-af6a-03c42c2c8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files.loc[multiple_files['counts']>=900].sort_values(by=['counts','spreadsheet_count'],ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43744f91-23af-4ecc-9098-bc8a304fb97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files.plot.scatter(x='spreadsheet_count',\n",
    "                      y='counts',\n",
    "                      c='spreadsheet_count',\n",
    "                      colormap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de7e59-cd8c-4f4e-96ff-8ab92887dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_related_identifiers = multiple_files.join(zenodo_related_identifiers.set_index('id'), on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7f1ebc-aa21-45ed-8479-c4840f98caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/25050141/how-to-filter-in-nan-pandas\n",
    "multiple_files_related_identifiers[~multiple_files_related_identifiers['related_identifiers'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7756578e-3e09-4e82-ab15-cefb3b13f738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for those with more than one spreadsheet uploaded\n",
    "multiple_files_spreadsheets = multiple_files.loc[multiple_files['spreadsheet_count']>1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce07641-c8d0-4a07-ac96-74f8d8128a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcd44bb-5080-4e53-8840-39117260d60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a plot with the percentage of spreadsheets on these multiple file records\n",
    "((multiple_files_spreadsheets['spreadsheet_count'] / multiple_files_spreadsheets['counts'])*100).plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9876aed-ea69-4ac7-a6c6-f8afddc212ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets['spreadsheet_count'].plot(kind='hist', legend=True, logy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28701ca7-9862-4602-834c-97f9b84da2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets_100plus = multiple_files_spreadsheets.loc[multiple_files_spreadsheets['spreadsheet_count']>=100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19a499-c898-4f93-9ad9-9e828e3d5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets_100plus[['spreadsheet_count']].plot(kind='hist', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece2e6db-f8e7-4563-b0f4-28fff79fd19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets.loc[multiple_files_spreadsheets['spreadsheet_count']>=400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac4b418-0407-42d6-b95b-4f9ffe56307f",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets['spreadsheet_count'].loc[multiple_files_spreadsheets['spreadsheet_count']>=400].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ec36d-644b-42f8-addf-dff844e2f637",
   "metadata": {},
   "outputs": [],
   "source": [
    "#would like to be able to plot counts and spreadsheet_counts together\n",
    "multiple_files_spreadsheets.drop(['filetype','id'], axis=1).plot(kind='box',legend=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f990afe3-e5c0-48d4-88ea-889b990f4f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_files_spreadsheets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af80605-99d7-47bd-b9d5-bf7985ed9c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "multiple_files.to_csv(f'multiple_files_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31835ba0-d857-4338-8c15-fce2760e7fcf",
   "metadata": {},
   "source": [
    "### File names indicating spreadsheet type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78e2c6-65fb-4475-ab40-16feb4fac641",
   "metadata": {},
   "source": [
    "#### Figure spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37624065-068c-4578-9baa-5fd8233cd011",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for filenames that indicate the spreadsheet file is a figure spreadsheet\n",
    "#https://note.nkmk.me/en/python-pandas-str-contains-match/\n",
    "figure_filenames = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext'].str.contains('fig[gure]*',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f255d0-aa93-45f6-b6ca-9011cc9a5238",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e301fe-2a42-4d2d-878b-cce68e60923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down figure spreadsheets by file type\n",
    "figure_filenames.groupby(['filetype']).agg({'fileid':'count'}).sort_values(by='fileid', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70036614-3e6e-447c-b422-2f7858c12d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the figure spreadsheets dataframe to a CSV for analysis in OpenRefine\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "figure_filenames.to_csv(f'figure_filenames_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e07524-0a8a-4758-b507-300a34e21a72",
   "metadata": {},
   "source": [
    "#### Database files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f4adab-bf35-4aa0-b201-cf74c35fa399",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for database or databank filenames in spreadsheet files\n",
    "database_filenames_spreadsheets = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext'].str.contains('(data)(.?)(base|bank)',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4ebab-389e-4546-94e4-dbdb6382f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filenames_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09686fdf-19d8-4b80-b27b-d3e83ca1b7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down figure spreadsheets by file type\n",
    "database_filenames_spreadsheets.groupby(['filetype']).agg({'fileid':'count'}).sort_values(by='fileid', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a081b9c-8beb-4a84-b99f-b4f10b421b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for database or databank filenames that are not spreadsheets\n",
    "database_filenames = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('(data)(.?)(base|bank)',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6d2dd9-775b-4bd7-8ca5-b02c89a23ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_filenames = database_filenames.loc[~database_filenames['filetype'].str.contains('\\.csv|\\.tsv|\\.xls[xbm]?|\\.xlt[xm]?|\\.ods|\\.ots|\\.ogw')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f9376a-7f15-44e4-8842-1eb8ac061f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#break down database files by file type\n",
    "database_filenames.groupby(['filetype']).agg({'fileid':'count'}).sort_values(by='fileid', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39325bd3-7979-4c52-a03b-203337b93834",
   "metadata": {},
   "source": [
    "#### Documentation files\n",
    "This includes files matching various patterns, such as including the word documentation, data dictionary, codebook, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1953e-96dc-4d81-8990-7c0adf6f7989",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look among all files for documentation filenames containing documentation, codebook, code book, data dictionary\n",
    "#TO DO: also look for metadata?\n",
    "documentation_filenames_spreadsheets = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext'].str.contains('documentation|code.?book|data.?dictionar.*',case=False)]\n",
    "documentation_filenames_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0f183e-c19f-4a9d-b67c-044e7059feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation_filenames = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('documentation|code.?book|data.?dictionar.*',case=False)]\n",
    "documentation_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515948a8-e242-48d1-a705-1337e556238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for readme files, not just spreadsheet files\n",
    "readme_files = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('read.?me',case=False)]\n",
    "readme_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856258c0-0d78-4f06-8815-c2451f3b4463",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for files containing text about, of any type\n",
    "#TO DO: check these results and drop rows that are not actually documentation files\n",
    "about_files = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('about',case=False)]\n",
    "about_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a663756-8f3a-4689-8512-138bd07e3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for files containing the word information (in several languages)\n",
    "#TO DO: check these results and drop rows that are not actually documentation files\n",
    "information_files = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('informa.ion.?',case=False)]\n",
    "information_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed3139a-91c4-4f01-9329-7e85144dc0ab",
   "metadata": {},
   "source": [
    "## File name best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ed747-69fc-4c8e-bdbd-c03845fc6189",
   "metadata": {},
   "source": [
    "### Use short file names\n",
    "Checks for filenames with extensions that are too long, too short, and at best practice length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d466baca-4f3c-4a45-a372-68877e3b248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext_len']>=200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a744d9b5-8029-4f07-8ff7-1b31d32d98ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext_len']>=200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ff208a-9b62-4434-9f0f-c334418e6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 characters, as recommended in https://caltechlibrary.github.io/RDMworkbook/file-organization-and-naming.html#file-naming\n",
    "zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext_len']>32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799a6327-ea07-45e1-b379-a23867279422",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext_len'] < 4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3100fb-da4e-4d52-ac98-428ba7fadac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python/filter-pandas-dataframe-with-multiple-conditions/\n",
    "zenodo_spreadsheet_files_df.loc[(zenodo_spreadsheet_files_df['filename_noext_len']>=4) & (zenodo_spreadsheet_files_df['filename_noext_len']<=32)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a83230-b2c5-4568-82e9-bbef46428ba1",
   "metadata": {},
   "source": [
    "### Use camel case (e.g, RainAvg) in file names.\n",
    "Using caseutil to check for cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919e347-01fc-44e7-8d1d-3a7da6f2fba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a column to the spreadsheet files dataframe that indicates what case caseutils thinks the filename with no extension is\n",
    "zenodo_spreadsheet_files_df['filename_cases'] = zenodo_spreadsheet_files_df['filename_noext'].apply(lambda x: filename_cases(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b797494-9a2b-43ca-9cf2-6fc3db3f44e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d052d9-0c7e-4e8f-8760-d45c5116077c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#where caseutil couldn't determine a case, fill those rows with value 'mixed'\n",
    "zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_cases'] == '', 'filename_cases'] = 'mixed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38aa88-1dee-49d7-8bb1-ff14fbfc0e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_groups = zenodo_spreadsheet_files_df.groupby(['filename_cases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11197ede-09dd-449e-a34a-a4905311ad4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ffe00c-855d-4c1c-9475-50cd6a55d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get counts of the different cases present\n",
    "zenodo_filename_cases_counts = zenodo_spreadsheet_files_groups.agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c579a4-7523-49af-9b32-f337286a46bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_filename_cases_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fd0219-bd4a-4d20-ba94-f11fc43f057f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_groups.get_group(('lower;upper',))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af414d-2c40-496d-9324-a5f448aa0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export csv files for each of the caseutil determinations, so they can be analyzed in OpenRefine\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "for key in zenodo_spreadsheet_files_groups.groups.keys():\n",
    "    print(key)\n",
    "    zenodo_spreadsheet_files_groups_cases = zenodo_spreadsheet_files_groups.get_group((key,))\n",
    "    newkey = key.replace(';','_')\n",
    "    print(newkey)\n",
    "    zenodo_spreadsheet_files_groups_cases.to_csv(f'zenodo_cases_{newkey}_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68e6333-829a-4cec-b6e9-52211d86172f",
   "metadata": {},
   "source": [
    "### Never include \"final\" in a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1884ec-167d-494a-8d94-31c0c787bb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for filenames that contain some variation of the word final\n",
    "final_filenames_spreadsheets = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext'].str.contains('final.?',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a46eb-e2e2-4786-844a-076433c7db00",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_filenames_spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b485ba-d384-453f-bea1-c8d65e2ce573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for files, not just spreadsheets, that contain the word final\n",
    "final_filenames = zenodo_files_df_deduped.loc[zenodo_files_df_deduped['filename_noext'].str.contains('final.?',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06f4b9c-84e0-4826-9e53-002432f42edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#group filenames containing the word final by file type\n",
    "final_filenames.groupby('filetype').agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8beed76b-c01d-4c6f-babf-e52002d77581",
   "metadata": {},
   "source": [
    "### Examine spaces and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d686dcb-3651-4ffd-b574-aa20b028163b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look for the following special characters: space\\.\\$@%#&\\*\\!\\(\\)\\{\\}\\[\\]~\\^`;<>,\\?\\'\\\"\\|\\=\n",
    "zenodo_spreadsheets_spaces_specialchars = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filename_noext'].str.contains('[ \\.\\$@%#&\\*\\!\\(\\)\\{\\}\\[\\]~\\^`;<>,\\?\\'\\\"\\|\\=]',case=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95226f4-db34-454c-9db8-e55245157e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an empty column for the kind of special character(s) found\n",
    "zenodo_spreadsheets_spaces_specialchars['char'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b856c-d37f-4a55-a37b-fbda06934d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd9ce069-4dba-4bc4-99ac-7779ec4b262d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('[&]', 'ampersand'), ('[<>]', 'angle-bracket'), ('[\\\\*]', 'asterisk'), ('[@]', 'at'), ('[`]', 'backtick'), ('[\\\\^]', 'caret'), ('[,]', 'comma'), ('[\\\\{\\\\}]', 'curly-bracket'), ('[]', 'degree'), ('[\\\\$]', 'dollar'), ('[\\\\\\\\\\\\\"]', 'double-quote'), ('[]', 'em-dash'), ('[]', 'emoji-check'), ('[]', 'emoji-x'), ('[]', 'en-dash'), ('[\\\\=]', 'equals'), ('[\\\\!]', 'exclamation'), ('[]', 'greater-equal'), ('[]', 'greek-alpha'), ('[]', 'greek-beta'), ('[]', 'greek-delta'), ('[]', 'greek-gamma'), ('[]', 'greek-lambda'), ('[]', 'greek-mu'), ('[]', 'greek-nu'), ('[]', 'greek-omicron'), ('[]', 'greek-sigma'), ('[]', 'greek-tau'), ('[]', 'increment'), ('[]', 'lenticular-bracket'), ('[]', 'ordinal-a'), ('[]', 'ordinal-o'), ('[\\\\(\\\\)]', 'parentheses'), ('[%]', 'percent'), ('[\\\\.]', 'period'), ('[\\\\|]', 'pipe'), ('[+]', 'plus'), ('[]', 'plus-minus'), ('[#]', 'pound'), ('[\\\\?]', 'question'), ('[]', 'question-diamond'), ('[;]', 'semicolon'), (\"[\\\\\\\\\\\\']\", 'single-quote'), ('[\\\\\\\\\\\\/]', 'slash'), ('[ ]', 'space'), ('[\\\\[\\\\]]', 'square-bracket'), ('[~]', 'tilde'), ('[]', 'times')]\n"
     ]
    }
   ],
   "source": [
    "#create a list of tuples containing the regex for a special character, plus the label for that character\n",
    "\n",
    "#https://blog.finxter.com/5-best-ways-to-create-a-list-of-tuples-from-csv-in-python/\n",
    "special_chars_list_df = pd.read_csv('special-chars-2025-12-16.csv')\n",
    "tuples_list = [tuple(x) for x in special_chars_list_df.to_numpy()]\n",
    "print(tuples_list)\n",
    "\n",
    "#characters = [('[ ]','space'),('[\\.]','period'),('[\\$]','dollar'),('[@]','at'),('[%]','percent'),('[#]','pound'),('[&]','ampersand'),('[\\*]','asterisk'),('[\\!]','exclamation'),('[\\(\\)]','parentheses'),('[\\{\\}]','curly-bracket'),('[\\[\\]]','square-bracket'),('[~]','tilde'),('[\\^]','caret'),('[`]','backtick'),('[;]','semicolon'),('[<>]','angle-bracket'),('[,]','comma'),('[\\?]','question'),('[\\\\\\']','single-quote'),('[\\\\\\\"]','double-quote'),('[\\|]','pipe'),('[]','en-dash'),('[]','em-dash'),('[\\=]','equals'),]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6823162-9acf-430e-8e91-b66c29a895ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through the list of tuples\n",
    "for char_regex, label in characters:\n",
    "    print(char_regex,label)\n",
    "    #find rows where filename contains the special character, then add the label to the char column\n",
    "    zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains(f'{char_regex}',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + f'{label};'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaac328-3532-4a87-85a6-8c137a37d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars['char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2aad30-dc7a-4028-9bb3-cac6b33fef04",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars['char'] = zenodo_spreadsheets_spaces_specialchars['char'].str.replace(';$','',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729703f-8142-4219-a44f-78a6748d7281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe to count the occurrences of the various special character combos\n",
    "zenodo_spreadsheets_spaces_specialchars_combinations = zenodo_spreadsheets_spaces_specialchars.groupby('char').agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb761f40-886c-4ac4-a7ab-4a3b4acb0093",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars_combinations.index.name = None\n",
    "zenodo_spreadsheets_spaces_specialchars_combinations.columns=['counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492942e0-81be-403b-9514-e1e0b42c2c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf14c61-21d8-4b98-acc5-2a21ac248bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars_combinations = zenodo_spreadsheets_spaces_specialchars_combinations.rename_axis(['chars']).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82805fb-e6e5-466e-a9a9-5df70e686525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for readability, create a new column called chars that replaces the semicolons with commas and spaces\n",
    "zenodo_spreadsheets_spaces_specialchars_combinations['chars'] = zenodo_spreadsheets_spaces_specialchars_combinations['chars'].str.replace(';',', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c155c7-8229-4470-a867-3dc86468507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6e3b6c-036c-4f31-be94-e05d623a704b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#explode the char column so we can count how many times each character occurs\n",
    "zenodo_spreadsheets_spaces_specialchars_explode = zenodo_spreadsheets_spaces_specialchars.assign(char=zenodo_spreadsheets_spaces_specialchars.char.str.split(';')).explode('char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50047fdb-cb50-4445-8805-cf033244255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars_explode.groupby(['char']).agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cdf1f7-07ea-4735-bbed-b1848ea16aa2",
   "metadata": {},
   "source": [
    "### Examine file names with no spaces or special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9036b0ef-1615-4a0d-a110-66f05ff2e496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the rows where the filenames do not contain any special characters\n",
    "zenodo_spreadsheets_no_spaces_specialchars = zenodo_spreadsheet_files_df.loc[~zenodo_spreadsheet_files_df['filename_noext'].str.contains('[ \\.\\$@%#&\\*\\!\\(\\)\\{\\}\\[\\]~\\^`;<>,\\?\\'\\\"\\|\\=]',case=False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd192861-24ee-434f-835a-78a2e2870bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_no_spaces_specialchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fab226-1b93-4d1c-bdf5-0dd4c15f37e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add a placeholder char column to later record what kind of non-special character is present\n",
    "zenodo_spreadsheets_no_spaces_specialchars['char'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfaa1ec7-17f7-43d1-8dca-5a6ff19e2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_no_spaces_specialchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a478304-f042-48bc-8d5d-f4a85661c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for filenames with no hyphens or underscores and fill those rows with the word 'none'\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[~zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('[_-]',case=False), 'char'] = zenodo_spreadsheets_no_spaces_specialchars['char'] + 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf5ec24-df22-488c-87c9-c0a8d258c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_no_spaces_specialchars.loc[~zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('[_-]',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e6a73-dcde-4037-b55e-74028d1aa69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "#look for various combinations of hyphens and underscores and add the type to the char column\n",
    "hyphen_underscore_regexes = [('^(?=.*_)(?:(?!-).)*$','underscore'),('^(?=.*-)(?:(?!_).)*$','hyphen'),('^(?=.*-)(?=.*_).*$','both')]\n",
    "for hyphen_underscore_regex, label in hyphen_underscore_regexes:\n",
    "    print(hyphen_underscore_regex,label)\n",
    "    zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains(f'{hyphen_underscore_regex}',case=False), 'char'] = zenodo_spreadsheets_no_spaces_specialchars['char'] + f'{label}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e466d2-ddfa-4cc3-bb65-29a329db1e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a count of occurrences of the different best practice characters (none, hyphens, underscores, or both)\n",
    "zenodo_spreadsheets_no_spaces_specialchars.groupby('char').agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72db1db1-4a69-491c-9918-3c14f827e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a count of occurrences of the different best practice characters (none, hyphens, underscores, or both)\n",
    "zenodo_spreadsheets_no_spaces_specialchars.groupby('char').agg({'fileid':'count'}).sort_values(by='fileid',ascending=False).plot(kind='pie', subplots=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0e871f-fae8-4d9e-a640-19163c78281c",
   "metadata": {},
   "source": [
    "### Look at special and best practice characters together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385aa862-3827-4a3e-bdc9-923ccdb74d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/how-to-concatenate-two-or-more-pandas-dataframes/\n",
    "zenodo_spreadsheets_chars = pd.concat([zenodo_spreadsheets_no_spaces_specialchars, zenodo_spreadsheets_spaces_specialchars],axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e1f131-4fec-4457-b6ba-d717d52bbde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars['capitalization'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbcbf6-8b3d-4562-b1ce-88b2faa43470",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars['capitalization'] = zenodo_spreadsheets_chars['filename_noext'].apply(lambda x: filename_capitalization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2962b315-cf88-4a8d-9cda-7cd1d2a5e4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2e3a11-0d78-4d89-a3e8-77fda938a7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_counts = zenodo_spreadsheets_chars.groupby('char').agg({'fileid':'count'}).sort_values(by='fileid',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ceb54b-39c8-4bd7-b407-59c848dcf331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a combined count of identified characters in filenames\n",
    "#https://btechgeeks.com/python-pandas-how-to-display-full-dataframe-i-e-print-all-rows-columns-without-truncation/\n",
    "print(zenodo_spreadsheets_chars_counts.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c172e8-bde2-42be-a3e9-9bff637300ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zenodo_spreadsheets_chars.groupby(['filename_cases','char','capitalization']).agg({'fileid':'count'}).sort_values(by=['filename_cases','fileid'],ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21a386-5c22-4bce-814a-2ffb2bb3c289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zenodo_spreadsheets_chars.groupby(['capitalization','char','filename_cases']).size().sort_values(ascending=False).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8555b5-e77b-4b09-ae24-b858e5e96d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_common = zenodo_spreadsheets_chars.groupby(['capitalization','char','filename_cases']).size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36dc606-5b30-49c1-9cc7-56ac8feb9893",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee749c56-ea7f-4aef-9839-8bc47b4dcc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_common_graph = zenodo_spreadsheets_chars_common.loc[zenodo_spreadsheets_chars.groupby(['capitalization','char','filename_cases']).size() > 7000].plot(kind='bar', color='purple', ylabel='Number of instances', xlabel='Cases and special chars', grid=True)\n",
    "\n",
    "#annotate bars\n",
    "zenodo_spreadsheets_chars_common_graph.bar_label(zenodo_spreadsheets_chars_common_graph.containers[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1750c264-1a5d-4440-bfaf-b83db5ee44b0",
   "metadata": {},
   "source": [
    "### Language of file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af25ac-ad7d-4599-9754-f4d5131b1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300484e-5380-455b-9076-a286be5dd2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace hyphens and underscores with spaces for langdetect process\n",
    "zenodo_spreadsheets_chars['filename_noext_spaces'] = zenodo_spreadsheets_chars['filename_noext'].str.replace('_|-',' ',regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77e67f8-2c06-4713-9266-e8b4e3d7418f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded59e8b-e2f4-49e3-a835-9fd0e5ccf959",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even optimized this takes 20 minutes\n",
    "zenodo_spreadsheets_chars['filename_lang'] = zenodo_spreadsheets_chars['filename_noext'].swifter.apply(detect_lang)\n",
    "#df['language'] = df['text_column'].swifter.apply(detect_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be179f9-5703-422e-a52d-472e80b8c533",
   "metadata": {},
   "outputs": [],
   "source": [
    "#even optimized this takes 20 minutes\n",
    "zenodo_spreadsheets_chars['filename_lang_spaces'] = zenodo_spreadsheets_chars['filename_noext_spaces'].swifter.apply(detect_lang)\n",
    "#df['language'] = df['text_column'].swifter.apply(detect_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dfffa6-a327-4e45-ad07-5c0732403a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_langs = zenodo_spreadsheets_chars.groupby('filename_lang').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c96fa9-b476-4c43-bf03-056422f9465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b339e5-0647-4990-a310-f90cfa6d5b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba300e43-aace-42d8-b299-4b1e4125541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheets_chars['filename_lang'].to_csv(f'zenodo_spreadsheets_chars_filename_lang_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e67070-f6d7-4b50-adb3-4ddca3697365",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheets_chars.to_csv(f'zenodo_spreadsheets_chars_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc60621a-66e0-4bdc-9dbd-af8c1bec1eca",
   "metadata": {},
   "source": [
    "## Create lists of record ids\n",
    "\n",
    "This section generates a list of all spreadsheet files, which can be used with zenodo_get to download all files. It also creates a sample of Excel and ODS files and a random sample of all files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7c4d3-efd6-45ca-a6cd-92f7765a8df1",
   "metadata": {},
   "source": [
    "### Random sample of 300 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecea144-6126-43c3-bce0-e7662aeb1718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample from 300 records\n",
    "#make a dataframe of just the spreadsheet files\n",
    "#from each record, select one spreadsheet file; \"if you've already seen this record id, skip this one'\n",
    "#groupby record id, then take one per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cb39b-9f72-48e9-8a9d-6e86de347620",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_300recs = zenodo_df_deduped.sample(n=300, random_state=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64560d54-643c-4326-846d-7e8a7bb8e27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_300recs['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6e384-ffe5-4fc5-b517-c502a6ca9d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unique record ids for these files\n",
    "zenodo_df_300recs_ids = zenodo_df_300recs['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac4851-31a5-4f22-a9ee-49871e4a5661",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_300recs = zenodo_spreadsheet_files_df.query('id in @zenodo_df_300recs_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad9da1a-df21-480c-b491-797e074f3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take just one spreadsheet file from each record\n",
    "zenodo_spreadsheet_files_df_300recs_sample = zenodo_spreadsheet_files_df_300recs.groupby('id').sample(n=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c0f8d5-2f83-4384-a36b-9d7ec63d5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_300recs_sample.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b2e41b-58b1-409f-a5f5-41fc2538504f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_300recs_sample['filesize_gb'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281fad0e-d80d-4ce8-826b-939aa46e3ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the count of each filetype as percentages\n",
    "zenodo_spreadsheet_files_df_300recs_sample.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']}).transform(lambda x: (x / 300) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca57838e-60df-4684-9322-7a5179436d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheet_files_df_300recs_sample.to_csv(f'zenodo_spreadsheet_files_df_300recs_sample_{filetime}.csv', index_label='df_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ea8c4-454c-40c7-9d9b-8f1097c9e7ca",
   "metadata": {},
   "source": [
    "### Random sample of 100 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f0d70b-5933-49ee-943c-156fa2ad2879",
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomly sample from 100 records\n",
    "#make a dataframe of just the spreadsheet files\n",
    "#from each record, select one spreadsheet file; \"if you've already seen this record id, skip this one'\n",
    "#groupby record id, then take one per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c252dc72-4031-4f36-bfe4-bd81e2977ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_100recs = zenodo_df_deduped.sample(n=100, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e501b00d-780f-4af8-9d01-d889b1263275",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_df_100recs['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733b72c7-9dbc-4ba3-a48f-21ec8ff4be58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unique record ids for these files\n",
    "zenodo_df_100recs_ids = zenodo_df_100recs['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fbe37b-848c-4dbb-9cbd-a48f4c497fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_100recs = zenodo_spreadsheet_files_df.query('id in @zenodo_df_100recs_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7475272a-7fb6-492a-890d-8f97b85b997e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take just one spreadsheet file from each record\n",
    "zenodo_spreadsheet_files_df_100recs_sample = zenodo_spreadsheet_files_df_100recs.groupby('id').sample(n=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea417c8-f6ba-4efa-8601-ac592e7e4a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_100recs_sample.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb81343-3ea3-4db7-a0de-0f7a6aa6ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_100recs_sample['filesize_gb'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50066078-e912-4a4d-a27d-06a3a36cd191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the count of each filetype as percentages\n",
    "zenodo_spreadsheet_files_df_100recs_sample.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']}).transform(lambda x: (x / 100) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855fbe9a-4210-4464-bdbb-8722abd55d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_100recs_sample.loc[zenodo_spreadsheet_files_df_100recs_sample['filetype']=='.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812ad11-df08-4ef3-8319-a0c989a5d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheet_files_df_100recs_sample.to_csv(f'zenodo_spreadsheet_files_df_100recs_sample_{filetime}.csv', index_label='df_index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3433fe4-6989-4dad-a09b-98368ecf441e",
   "metadata": {},
   "source": [
    "### Make lists for zenodo_get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f7b693-863f-431e-b6ef-3a7d9b6f5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make one text file of all ids\n",
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "zenodo_spreadsheet_files_ids = zenodo_spreadsheet_files_df['id'].unique()\n",
    "np.savetxt(f'zenodo_spreadsheet_file_ids_{filetime}.csv', zenodo_spreadsheet_files_ids, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a0f11-8887-42ed-8352-0390bde74c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482802c-64a3-431a-8d79-580a5c665cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make text files of ids by file type\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5771ddbe-0a2b-43b5-aa83-0f9c8ea3c3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#want to make a list of ids for each subgroup\n",
    "zenodo_spreadsheet_files_df.groupby(['filetype']).groups.keys()\n",
    "#zenodo_spreadsheet_files_df.iloc[gb.groupby.indices.get(filetype)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d436d654-54c8-42d3-92e4-feb46c72c2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_csv_ids = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filetype'] == '.csv']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7454e6-3264-4cab-a1a1-d20fcd9d9d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_csv_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8189751c-695a-4aad-bdac-0fc169467a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheet_files_csv_ids.to_csv(f'csv_ids_{filetime}.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2edb4c-7897-4821-9508-639f1425b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "for key in zenodo_spreadsheet_files_df.groupby(['filetype']).groups.keys():\n",
    "#zenodo_spreadsheet_files_df.groupby(['filetype']).groups.keys():\n",
    "    print(key)\n",
    "    zenodo_spreadsheet_files_ids = zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['filetype'] == key]['id'].unique()\n",
    "    #print(zenodo_spreadsheet_files_ids)\n",
    "    #print(zenodo_spreadsheet_files_ids)\n",
    "    newkey = key.strip('.')\n",
    "    print(newkey)\n",
    "    np.savetxt(f'{newkey}_ids_{filetime}.csv', zenodo_spreadsheet_files_ids, fmt='%d')\n",
    "    # print(f'{key}_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c08d707-756b-44c2-8317-a59a57d09f4b",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6765ac4f-ee3c-4db1-b330-f9a387111dfe",
   "metadata": {},
   "source": [
    "### Create samples of 100 records for selected filetypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abbc08-9c50-4ec3-9f5d-c54555c94288",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_groups = zenodo_spreadsheet_files_df.groupby(['filetype'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118b49f-0cc6-4000-841c-b2784ec358fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9c7c1-5b08-4db1-8ce8-de67eda6a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_group = zenodo_spreadsheet_groups.get_group(('.csv',))\n",
    "csv_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e33b8-055e-43d8-b8e7-1e40292f684b",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_sample = csv_group.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56788895-41f9-4ae6-8aac-b8ff5b21115e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "csv_sample.to_csv(f'csv_sample_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e889c-5246-487f-b332-c75c7f75af4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_group = zenodo_spreadsheet_groups.get_group(('.tsv',))\n",
    "tsv_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b3af20-f3b5-4f08-8d81-370c2ea79a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_sample = tsv_group.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5d6019-0217-4d66-8aab-e317a261dadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "tsv_sample.to_csv(f'tsv_sample_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbbc9ba-cec2-421b-9393-7400888e84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls, xlsm, ods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed152f75-fbcf-47c4-9c13-5009cb27741e",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_group = zenodo_spreadsheet_groups.get_group(('.xls',))\n",
    "xls_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaeb1bd2-2cec-4b70-8a1b-2c628887d2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "xls_sample = xls_group.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6f2963-9a1c-44ae-a6dc-3ab535a5a4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "xls_sample.to_csv(f'xls_sample_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b657b-255a-4542-9d6a-79d6468896e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8d7869-8985-4fa6-8399-83122e3327c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsm_group = zenodo_spreadsheet_groups.get_group(('.xlsm',))\n",
    "xlsm_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8025480d-5d1d-4cff-bd65-a9d9219b1a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlsm_sample = xlsm_group.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563b1729-b205-4a3c-82ba-17f5a6ca2b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "xlsm_sample.to_csv(f'xlsm_sample_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3e62b-4e1f-480a-851a-1bcd1e512c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_group = zenodo_spreadsheet_groups.get_group(('.ods',))\n",
    "ods_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5f4d43-e5c3-483b-bdf1-bf73d7e4aa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ods_sample = ods_group.sample(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90b03b6-bc2b-4e9e-a031-b33c5cb0b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "ods_sample.to_csv(f'ods_sample_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e708d-2e10-4d37-a223-c8cad42abbbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116615c3-13b0-4ad7-ab5a-227815e90577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#period\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\.',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'period;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35539bd-8356-42ca-b859-e1b4cd238798",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\.',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5920d5-5d16-48aa-866d-84010945fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#space\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains(' ',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'space;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262718e4-f477-42ef-aea9-8332a446fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains(' ',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea4b31-7997-444d-976c-1adc0974da5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dollar\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\$',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'dollar;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032a9bea-29b2-4ac0-aae6-e3487e63d789",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\$',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171704d0-a8fc-42cc-b083-45ae75a15c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at symbol\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('@',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'at;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb24c6b-42f9-41ef-8927-88dfef93c760",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('@',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7b62a9-cfe6-43e5-8baf-83af5bdbca35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent sign\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('%',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'percent;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8806c4-6f83-4add-854e-afd9d40bc015",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('%',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b717c59-73d9-4301-ac5e-2a01e9a8297b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pound sign\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('#',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'pound;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3088e36a-f957-44ec-a961-89afea858254",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('#',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29167780-d764-425b-96db-ba3ff5d2ce63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ampersand\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('&',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'ampersand;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89114674-8c00-45dc-b3ad-c84486bbdd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('&',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd13c6f4-2468-422c-9cb4-54764255c1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asterisk\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\*',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'asterisk;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82838345-0417-47b3-b1ab-b3d5e20c8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\*',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6f147-1e2f-49d3-be99-6f291c1e1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parentheses\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\(\\)]',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'parentheses;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c494888-9ace-406a-a629-633f1b7fb249",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\(\\)]',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fecea06-1e37-4ac7-83d0-442684fb7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#curly bracket\n",
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\{\\}]',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'curly-bracket;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534f931-302e-46c4-8a7f-755260a5ce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\{\\}]',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecf321f-c225-4d8b-84b7-ee2a15deb97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\[\\]]',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'square-bracket;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01e66cb-184d-408c-9327-0f3370d003bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('[\\[\\]]',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb502d-a8b7-46f6-a702-de9b2dbcef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\!',case=False), 'char'] = zenodo_spreadsheets_spaces_specialchars['char'] + 'exclamation;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72887e58-108c-4434-8766-973063b6197f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\!',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7a2ded-ab0e-408d-846b-fc160d6b51f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheets_spaces_specialchars.loc[zenodo_spreadsheets_spaces_specialchars['filename_noext'].str.contains('\\!',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25cce88-f635-47c3-bf8b-c67c586772bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for just underscores, no hyphens\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*_)(?:(?!-).)*$',case=False), 'char'] = zenodo_spreadsheets_no_spaces_specialchars['char'] + 'underscore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae791a5-8118-4dd7-8afd-4c686705ab4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for just underscores, no hyphens\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*_)(?:(?!-).)*$',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15920870-91e7-44a0-bd6a-9065771271cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for just hyphens, no underscores\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*-)(?:(?!_).)*$',case=False), 'char'] = zenodo_spreadsheets_no_spaces_specialchars['char'] + 'hyphen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe3f8d-d1e0-4b58-b2e8-adeca13ef76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for just hyphens, no underscores\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*-)(?:(?!_).)*$',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8c76c-da95-493b-9e99-b4bd36e30222",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for both hyphens and underscores\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*-)(?=.*_).*$',case=False), 'char'] = zenodo_spreadsheets_no_spaces_specialchars['char'] + 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cc3620-4dfc-45e0-bd2c-c4d4ba9619bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://superuser.com/questions/1335621/creating-a-regex-expression-with-a-not-condition-for-a-specific-substring\n",
    "# look for both hyphens and underscores\n",
    "zenodo_spreadsheets_no_spaces_specialchars.loc[zenodo_spreadsheets_no_spaces_specialchars['filename_noext'].str.contains('^(?=.*-)(?=.*_).*$',case=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4862d5cd-29a6-4b86-80ce-fd952e686e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/pandas-dev/pandas/issues/8121#issuecomment-53578872\n",
    "#gr = zenodo_spreadsheet_files_df.groupby(pd.factorize(zenodo_spreadsheet_files_df.filename_cases)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab3a49-5a78-4ac6-9080-a2349ce147e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gr.get_group(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9886b29-3a2e-42af-9d52-bc066f569ee9",
   "metadata": {},
   "source": [
    "### Make list for testing other scripts\n",
    "List will be used to test zenodo_get bash script, Jupyter notebook for creating the downloaded file inventory, and code in this notebook for comparing metadata and files dataframes to inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef11d3fd-6763-4fad-a411-68e720b14643",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of files\n",
    "zenodo_spreadsheet_files_df_sample = zenodo_spreadsheet_files_df.groupby(['filetype']).sample(frac=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0df21c-c942-449c-8b8a-c73dcb4d9b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8997d5-a9c7-41b5-a89e-6ffe920834cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample.groupby(['filetype']).agg({'id': 'count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf46d6-64e6-44d4-8d74-38ea5dc5796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unique record ids for these files\n",
    "zenodo_spreadsheet_files_df_sample_ids = zenodo_spreadsheet_files_df_sample['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3900184-1acd-4395-95e6-5383464cb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "#count how many unique record ids there actually are\n",
    "len(zenodo_spreadsheet_files_df_sample_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be52c3ab-9563-4e68-b672-1ae8fe5e8a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using that unique list of ids, make a dataframe listing all the spreadsheet files associated with these ids\n",
    "#this is more than the sample of 100, since many records have more than one spreadsheet file uploaded\n",
    "zenodo_spreadsheet_files_df_sample_all = zenodo_spreadsheet_files_df.query('id in @zenodo_spreadsheet_files_df_sample_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fee4b74-44d8-4c39-a53d-3e5ba9f4c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7409cb-e81c-4e7d-af55-ef1e6f9a207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_sample_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546f5f1-fd6c-4ffc-a86a-0629ce611881",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_sample_all['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9204af6-43b2-4924-9d49-445e8d834e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a dataframe that counts how many spreadsheets there are uploaded to each record by grouping by record id.\n",
    "#filter down to those with fewer than 10 files\n",
    "zenodo_spreadsheet_files_df_sample_all_counts = zenodo_spreadsheet_files_df_sample_all.groupby(['id']).count() <= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fdb25e-ccfe-4238-af1b-834ec4b39b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get just the ones that evaluate as \"true\"\n",
    "#https://www.statology.org/pandas-filter-by-boolean-column/\n",
    "zenodo_spreadsheet_files_df_sample_all_counts.loc[zenodo_spreadsheet_files_df_sample_all_counts.fileid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845b472-0513-41ac-9ce8-531045db6f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#put the ones with 10 or fewer spreadsheets in a dataframe\n",
    "zenodo_spreadsheet_files_df_sample_all_counts_small = zenodo_spreadsheet_files_df_sample_all_counts.loc[zenodo_spreadsheet_files_df_sample_all_counts.fileid].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8267c-21b1-41a3-a12b-e327f1718427",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_sample_all_counts_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618489bc-e1eb-40cf-8d95-4290014639d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use that list of records with fewer than 10 spreadsheets uploaded to filter files\n",
    "zenodo_spreadsheet_files_df_sample_records_small = zenodo_spreadsheet_files_df_sample_all.query('id in @zenodo_spreadsheet_files_df_sample_all_counts_small')\n",
    "#.groupby('filetype').groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c261f3-6928-4334-91bd-230dddb492e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_sample_records_small.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025fcaa6-2aef-4d0d-9822-1356f691b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_records_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9736264-7ace-4ca9-a390-ce33b4464f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_records_small_size = zenodo_spreadsheet_files_df_sample_records_small['filesize'].sum()\n",
    "print(format_bytes(zenodo_spreadsheet_files_df_sample_records_small_size, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be359a-daf8-4d0b-b88f-d68b4e590a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_records_small.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a209691-ff22-4491-ba15-b2ca7bc114cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_records_small_ids = zenodo_spreadsheet_files_df_sample_records_small['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a86b0c-b329-4f92-9e41-8022e1381074",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "np.savetxt(f'zenodo_spreadsheet_files_df_sample_records_small_ids_{filetime}.csv', zenodo_spreadsheet_files_df_sample_records_small_ids, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae93c33-bfdf-4c7d-b649-ef67f67ba00c",
   "metadata": {},
   "source": [
    "### Take a random sample of files for file-level analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e52008-ea19-4ce3-b5c4-48bfc1614c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of files\n",
    "zenodo_spreadsheet_files_df_random_sample01 = zenodo_spreadsheet_files_df.groupby(['filetype']).sample(frac=0.01, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461116ff-d20f-48e6-ae6b-b563c1a32e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zenodo_spreadsheet_files_df_random_sample01_size = \n",
    "zenodo_spreadsheet_files_df_random_sample01['filesize_gb'].sum()\n",
    "#print(format_bytes(zenodo_spreadsheet_files_df_sample_records_small_size, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e091fd-0bba-4d1d-a281-d5b2b7b7cf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of files\n",
    "zenodo_spreadsheet_files_df_random_sample001 = zenodo_spreadsheet_files_df.groupby(['filetype']).sample(frac=0.001, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fe2a54-cce6-428a-9477-331475a63689",
   "metadata": {},
   "outputs": [],
   "source": [
    "#zenodo_spreadsheet_files_df_random_sample01_size = \n",
    "zenodo_spreadsheet_files_df_random_sample001['filesize_gb'].sum()\n",
    "#print(format_bytes(zenodo_spreadsheet_files_df_sample_records_small_size, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9d08a-0e7d-444e-aa3f-da8fdc3739fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_random_sample001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb175481-3dbc-4f3c-b1a2-44ed6cfbae46",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_random_sample001.groupby(['filetype']).agg({'filetype': ['count'], 'filesize_gb': ['sum']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550418b-e534-47cb-bf05-02c937bea3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "zenodo_spreadsheet_files_df_random_sample001.to_csv(f'zenodo_spreadsheet_files_df_random_sample001_{filetime}.csv', index_label='df_index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3671fdf3-5276-4da3-8326-6a778e57dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_random_sample01.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f929683-5e82-4a92-9f0e-ae15cc78ee55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the unique record ids for these files\n",
    "#zenodo_spreadsheet_files_df_random_sample001_ids = \n",
    "zenodo_spreadsheet_files_df_random_sample001['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296618ac-1519-46e0-9685-53a65531759d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in zenodo_spreadsheet_files_df_random_sample001['filelinks.self']:\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2931c81-2054-445b-ae0f-9fd423db988c",
   "metadata": {},
   "source": [
    "## sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7198d5-5897-4f6f-9ac6-d71d71fb411d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e584171-c429-4f1f-ad1d-218fee59d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.w3schools.in/python/examples/language-detection\n",
    "#https://stackoverflow.com/questions/39142778/how-to-determine-the-language-of-a-piece-of-text\n",
    "x='Subir_Seleccion_Maquinal'\n",
    "detect_lang(x)\n",
    "#print(languages)\n",
    "# try:\n",
    "#     languages = detect_langs(x)\n",
    "#     lang_string = ''\n",
    "#     for language in languages:\n",
    "#         lang_code = language.lang\n",
    "#         #print(lang_code)\n",
    "#         lang_prob = str(language.prob)\n",
    "#         #print(lang_prob)\n",
    "#         lang_string += lang_code +';'+lang_prob +'|'\n",
    "#     print(lang_string)\n",
    "# except Exception as e:\n",
    "#     print(e)\n",
    "# # Sample Output:\n",
    "# # en 0.50 (English)\n",
    "# # hi 0.50 (Hindi)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a69c99-395c-4e4e-87a5-1a27908ed03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_ods_filetypes = ['.xls','.xlsb','.xlsx','.xltx','.ods','.ots','.xlsm','.xltm','.xltx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b5a2a-bca8-488a-96e8-e897c4766832",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19960077/how-to-filter-pandas-dataframe-using-in-and-not-in-like-in-sql\n",
    "excel_ods_files = zenodo_spreadsheet_files_df.query('filetype in @excel_ods_filetypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c166671-5e90-4671-99eb-28d48f4b2d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_ods_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1f786-ffe1-4417-9f48-dcb27c289feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41286569/get-total-of-pandas-column\n",
    "excel_ods_filesize_total = excel_ods_files['filesize'].sum()\n",
    "print(excel_ods_filesize_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa5a044-ee0e-4054-9e3b-14e8d1e67b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "excel_ods_files['id'].to_csv(f'excel_ods_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201acd48-40b3-4700-b814-0fe31a1f9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #filetime = datetime.now()\n",
    "# # filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "# zenodo_spreadsheet_files_df['id'].to_csv(f'zenodo_spreadsheet_files_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fad2c6b-e4c7-44bf-a0a1-cf6fd033166a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a random sample of a small fraction of files files\n",
    "#zenodo_spreadsheet_files_df_sample = zenodo_spreadsheet_files_df.groupby(['filetype']).sample(frac=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1f1b64-b716-4920-84d0-a9f9fe2ea9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spreadsheet_sample_files_ids = zenodo_spreadsheet_files_df_sample_records_small.loc[zenodo_spreadsheet_files_df_sample_records_small['filetype'] == '.tsv']['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2ee8b1-6d42-4677-9dd4-cd52aadc187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_spreadsheet_sample_files_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20d0d81-d17c-4e14-8b4d-c87f8be1090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zenodo_spreadsheet_sample_files_ids = zenodo_spreadsheet_files_df_sample_records_small.loc[zenodo_spreadsheet_files_df_sample_records_small['filetype'] == key]['id'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18b850-4640-4c2b-b4db-28e0bc7d87db",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('unique_spreadsheet_sample_files_ids.txt', unique_spreadsheet_sample_files_ids, fmt='%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f1be79-dd17-4842-aeb4-83edd0f76a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "for key in zenodo_spreadsheet_files_df_sample_records_small.groupby(['filetype']).groups.keys():\n",
    "#zenodo_spreadsheet_files_df.groupby(['filetype']).groups.keys():\n",
    "    print(key)\n",
    "    zenodo_spreadsheet_sample_files_ids = zenodo_spreadsheet_files_df_sample_records_small.loc[zenodo_spreadsheet_files_df_sample_records_small['filetype'] == key]['id'].unique()\n",
    "    #print(zenodo_spreadsheet_files_ids)\n",
    "    newkey = key.strip('.')\n",
    "    print(newkey)\n",
    "    #https://www.geeksforgeeks.org/how-to-save-a-numpy-array-to-a-text-file/\n",
    "    np.savetxt(f'{newkey}_small_sample_ids_{filetime}.csv', zenodo_spreadsheet_sample_files_ids, fmt='%d')\n",
    "    # print(f'{key}_ids_{filetime}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383899bc-b3d4-4114-8f24-a53e5acb8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_ods_files_sample = excel_ods_files.sample(n=100, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a59fb-9aa4-4854-9f77-526d51400f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_ods_files_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030a69ef-3f2b-4ba3-9c25-15b551c84883",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "\n",
    "excel_ods_files_sample['id'].to_csv(f'excel_ods_files_sample_{filetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4056315-4912-45a1-b4dd-60b329896152",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_percentage = zenodo_spreadsheet_files_df.sample(frac=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df95bce-8538-46a7-a2d0-08f6f06b0a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41286569/get-total-of-pandas-column\n",
    "len(zenodo_spreadsheet_files_df_sample_percentage.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732aeaf2-cdf4-4fa1-bfcd-6374d701a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41286569/get-total-of-pandas-column\n",
    "zenodo_spreadsheet_files_df_sample_percentage_size = zenodo_spreadsheet_files_df_sample_percentage['filesize'].sum()\n",
    "print(format_bytes(zenodo_spreadsheet_files_df_sample_percentage_size, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d8d1b-6ede-43ba-9aff-1f6084b2c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_percentage_ids = zenodo_spreadsheet_files_df_sample_percentage['id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4277207-898b-45c1-b65e-ec339bd68993",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_percentage_all = zenodo_spreadsheet_files_df.query('id in @zenodo_spreadsheet_files_df_sample_percentage_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e4424-c1d8-4e33-90a0-a5f83fa38846",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zenodo_spreadsheet_files_df_sample_percentage_all.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a326af-3bb0-4cde-9602-a9b6a2bbf951",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_percentage_all_size = zenodo_spreadsheet_files_df_sample_percentage_all['filesize'].sum()\n",
    "print(format_bytes(zenodo_spreadsheet_files_df_sample_percentage_all_size, 'GB', SI=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cbb511-041e-4def-9b0a-e872482a5ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df_sample_percentage_all.groupby(['filetype']).agg({'filetype': ['count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ae1a6-71d4-4dca-85d7-63447f2e5980",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_spreadsheet_files_df.loc[zenodo_spreadsheet_files_df['id'] == 12805219]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
