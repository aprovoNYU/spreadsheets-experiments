{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a9964d-8cea-48ee-afec-59c08d54f0fc",
   "metadata": {},
   "source": [
    "# Downloaded spreadsheet file inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9abcee14-8c81-40bb-955c-f64665b19012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3b5dbde-62e0-4fc8-b56d-0de360a53dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "3520917\n",
      "['3520917']\n",
      "10606483\n",
      "['10606483']\n",
      "10606483\n",
      "['10606483']\n",
      "10606483\n",
      "['10606483']\n",
      "10606483\n",
      "['10606483']\n",
      "7326500\n",
      "['7326500']\n",
      "11165918\n",
      "['11165918']\n",
      "11165918\n",
      "['11165918']\n",
      "11165918\n",
      "['11165918']\n",
      "11165918\n",
      "['11165918']\n",
      "7576974\n",
      "['7576974']\n",
      "5042194\n",
      "['5042194']\n",
      "7692555\n",
      "['7692555']\n",
      "7692555\n",
      "['7692555']\n",
      "7692555\n",
      "['7692555']\n",
      "7692555\n",
      "['7692555']\n",
      "13236575\n",
      "['13236575']\n",
      "10118192\n",
      "['10118192']\n",
      "10118192\n",
      "['10118192']\n",
      "10118192\n",
      "['10118192']\n",
      "10118192\n",
      "['10118192']\n",
      "10118192\n",
      "['10118192']\n",
      "10118192\n",
      "['10118192']\n",
      "5770442\n",
      "['5770442']\n",
      "5770442\n",
      "['5770442']\n",
      "5770442\n",
      "['5770442']\n",
      "5770442\n",
      "['5770442']\n",
      "5770442\n",
      "['5770442']\n",
      "6984998\n",
      "['6984998']\n",
      "6984998\n",
      "['6984998']\n",
      "6984998\n",
      "['6984998']\n"
     ]
    }
   ],
   "source": [
    "# modified Google Gemini output\n",
    "\n",
    "path_obj = Path('/Volumes/ap180/spreadsheets_corpus')\n",
    "data = []\n",
    "max_depth = 0\n",
    "\n",
    "# Iterate through all files and directories recursively\n",
    "# We use rglob('*') to find all items, but only process files.\n",
    "for item in path_obj.rglob('*'):\n",
    "    if item.is_file(): # Only process files\n",
    "        row_data = {\n",
    "            'Directory': str(path_obj.name), # The name of the root directory being scanned\n",
    "            'File': item.name,              # The name of the file\n",
    "            'Type': 'File'                  # Type is always 'File'\n",
    "        }\n",
    "\n",
    "        current_level_parts = [] # To store the components of the subdirectory path for the current file\n",
    "\n",
    "        # For a file, the subdirectory levels are determined by its parent's path relative to the root\n",
    "        if item.parent != path_obj: # Check if the parent is not the root directory itself\n",
    "            relative_parent_path = item.parent.relative_to(path_obj)\n",
    "            print(relative_parent_path)\n",
    "            current_level_parts = list(relative_parent_path.parts)\n",
    "            print(current_level_parts)\n",
    "\n",
    "        # Update the maximum depth found across all items to know how many level columns to create\n",
    "        max_depth = max(max_depth, len(current_level_parts))\n",
    "\n",
    "        # Assign each part of the subdirectory path to its respective 'Subdirectory_Level_X' column\n",
    "        for i, part in enumerate(current_level_parts):\n",
    "            row_data[f'Subdirectory_Level_{i + 1}'] = part\n",
    "\n",
    "        data.append(row_data)\n",
    "\n",
    "# Create the initial DataFrame from the collected data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Ensure all potential 'Subdirectory_Level_X' columns exist and fill any missing values (NaNs)\n",
    "# with empty strings for shallower paths (e.g., files directly in root)\n",
    "for i in range(1, max_depth + 1):\n",
    "    col_name = f'Subdirectory_Level_{i}'\n",
    "    if col_name not in df.columns:\n",
    "        df[col_name] = '' # Add column if it was not present in any row data\n",
    "    df[col_name] = df[col_name].fillna('') # Fill NaN values with empty strings\n",
    "\n",
    "# Define the desired order of columns in the final DataFrame\n",
    "ordered_columns = ['Directory']\n",
    "for i in range(1, max_depth + 1):\n",
    "    ordered_columns.append(f'Subdirectory_Level_{i}')\n",
    "ordered_columns.extend(['File', 'Type'])\n",
    "\n",
    "# Filter the ordered_columns list to only include columns that actually exist in the DataFrame\n",
    "df = df[[col for col in ordered_columns if col in df.columns]]\n",
    "\n",
    "# Sort the DataFrame for better readability.\n",
    "# The sort keys are dynamically constructed based on the available subdirectory level columns.\n",
    "sort_by_cols = ['Directory']\n",
    "for i in range(1, max_depth + 1):\n",
    "    if f'Subdirectory_Level_{i}' in df.columns:\n",
    "        sort_by_cols.append(f'Subdirectory_Level_{i}')\n",
    "sort_by_cols.append('File')\n",
    "df = df.sort_values(by=sort_by_cols).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe7adc71-f103-4b9c-8a9d-e3d844ea278e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Directory</th>\n",
       "      <th>Subdirectory_Level_1</th>\n",
       "      <th>File</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td></td>\n",
       "      <td>.DS_Store</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>Eukaryotic_virus_CV_Dataset-1.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>Prokaryotic_virus_CV_Dataset-1.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>Test_Eukaryotic_virus_Dataset-1.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>Test_Prokaryotic_virus_Dataset-1.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>gut_virome.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10118192</td>\n",
       "      <td>marine_virome_id.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10606483</td>\n",
       "      <td>Grain Size of Modern TX Environments.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10606483</td>\n",
       "      <td>MAI49 and MAI35 210Pb 137Cs.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10606483</td>\n",
       "      <td>MAI49 and MAI35 Grain Size.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>10606483</td>\n",
       "      <td>MAI49 and Modern Environments XRF.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>11165918</td>\n",
       "      <td>cellref_markers_celltype_level3_results.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>11165918</td>\n",
       "      <td>hlca_markers_ann_finest_level_results.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>11165918</td>\n",
       "      <td>nsforest_markers_ann_finest_level_results.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>11165918</td>\n",
       "      <td>nsforest_markers_celltype_level3_results.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>13236575</td>\n",
       "      <td>Q128490596.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>Behaviour2.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>E2metano.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>E2metano24.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>E2metano48.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>E2metano6.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>RP.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>3520917</td>\n",
       "      <td>taxa_boc.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5042194</td>\n",
       "      <td>Figure 3D Malachite.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5770442</td>\n",
       "      <td>UBABIOCIDES.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5770442</td>\n",
       "      <td>UBABIOCIDES.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5770442</td>\n",
       "      <td>UBABIOCIDES_ProductTypes.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5770442</td>\n",
       "      <td>UBABIOCIDES_WorkPackageNotes.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>5770442</td>\n",
       "      <td>UBABIOCIDES_WorkPackages.csv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>6984998</td>\n",
       "      <td>EfficiencyEvaluation.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>6984998</td>\n",
       "      <td>characterizationQRNG.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>6984998</td>\n",
       "      <td>measuredPhotonStatistics.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7326500</td>\n",
       "      <td>Complete_dataset_Xyleborini.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7576974</td>\n",
       "      <td>daftar regulasi jdih pemalang-new.xlsx</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7692555</td>\n",
       "      <td>SupplementaryFile1.HPRCy1v2genbank.self.s50k.l...</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7692555</td>\n",
       "      <td>SupplementaryFile4.eid0900.tsv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7692555</td>\n",
       "      <td>SupplementaryFile7.chm13v2.PRDM9.tsv</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>spreadsheets_corpus</td>\n",
       "      <td>7692555</td>\n",
       "      <td>SupplementaryFile8.chrACRO+refs.pq_contigs.1kb...</td>\n",
       "      <td>File</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Directory Subdirectory_Level_1  \\\n",
       "0   spreadsheets_corpus                        \n",
       "1   spreadsheets_corpus             10118192   \n",
       "2   spreadsheets_corpus             10118192   \n",
       "3   spreadsheets_corpus             10118192   \n",
       "4   spreadsheets_corpus             10118192   \n",
       "5   spreadsheets_corpus             10118192   \n",
       "6   spreadsheets_corpus             10118192   \n",
       "7   spreadsheets_corpus             10606483   \n",
       "8   spreadsheets_corpus             10606483   \n",
       "9   spreadsheets_corpus             10606483   \n",
       "10  spreadsheets_corpus             10606483   \n",
       "11  spreadsheets_corpus             11165918   \n",
       "12  spreadsheets_corpus             11165918   \n",
       "13  spreadsheets_corpus             11165918   \n",
       "14  spreadsheets_corpus             11165918   \n",
       "15  spreadsheets_corpus             13236575   \n",
       "16  spreadsheets_corpus              3520917   \n",
       "17  spreadsheets_corpus              3520917   \n",
       "18  spreadsheets_corpus              3520917   \n",
       "19  spreadsheets_corpus              3520917   \n",
       "20  spreadsheets_corpus              3520917   \n",
       "21  spreadsheets_corpus              3520917   \n",
       "22  spreadsheets_corpus              3520917   \n",
       "23  spreadsheets_corpus              5042194   \n",
       "24  spreadsheets_corpus              5770442   \n",
       "25  spreadsheets_corpus              5770442   \n",
       "26  spreadsheets_corpus              5770442   \n",
       "27  spreadsheets_corpus              5770442   \n",
       "28  spreadsheets_corpus              5770442   \n",
       "29  spreadsheets_corpus              6984998   \n",
       "30  spreadsheets_corpus              6984998   \n",
       "31  spreadsheets_corpus              6984998   \n",
       "32  spreadsheets_corpus              7326500   \n",
       "33  spreadsheets_corpus              7576974   \n",
       "34  spreadsheets_corpus              7692555   \n",
       "35  spreadsheets_corpus              7692555   \n",
       "36  spreadsheets_corpus              7692555   \n",
       "37  spreadsheets_corpus              7692555   \n",
       "\n",
       "                                                 File  Type  \n",
       "0                                           .DS_Store  File  \n",
       "1                   Eukaryotic_virus_CV_Dataset-1.csv  File  \n",
       "2                  Prokaryotic_virus_CV_Dataset-1.csv  File  \n",
       "3                 Test_Eukaryotic_virus_Dataset-1.csv  File  \n",
       "4                Test_Prokaryotic_virus_Dataset-1.csv  File  \n",
       "5                                      gut_virome.csv  File  \n",
       "6                                marine_virome_id.csv  File  \n",
       "7           Grain Size of Modern TX Environments.xlsx  File  \n",
       "8                    MAI49 and MAI35 210Pb 137Cs.xlsx  File  \n",
       "9                     MAI49 and MAI35 Grain Size.xlsx  File  \n",
       "10             MAI49 and Modern Environments XRF.xlsx  File  \n",
       "11        cellref_markers_celltype_level3_results.csv  File  \n",
       "12          hlca_markers_ann_finest_level_results.csv  File  \n",
       "13      nsforest_markers_ann_finest_level_results.csv  File  \n",
       "14       nsforest_markers_celltype_level3_results.csv  File  \n",
       "15                                     Q128490596.csv  File  \n",
       "16                                     Behaviour2.csv  File  \n",
       "17                                       E2metano.csv  File  \n",
       "18                                     E2metano24.csv  File  \n",
       "19                                     E2metano48.csv  File  \n",
       "20                                      E2metano6.csv  File  \n",
       "21                                             RP.csv  File  \n",
       "22                                       taxa_boc.csv  File  \n",
       "23                           Figure 3D Malachite.xlsx  File  \n",
       "24                                    UBABIOCIDES.csv  File  \n",
       "25                                   UBABIOCIDES.xlsx  File  \n",
       "26                       UBABIOCIDES_ProductTypes.csv  File  \n",
       "27                   UBABIOCIDES_WorkPackageNotes.csv  File  \n",
       "28                       UBABIOCIDES_WorkPackages.csv  File  \n",
       "29                          EfficiencyEvaluation.xlsx  File  \n",
       "30                          characterizationQRNG.xlsx  File  \n",
       "31                      measuredPhotonStatistics.xlsx  File  \n",
       "32                   Complete_dataset_Xyleborini.xlsx  File  \n",
       "33             daftar regulasi jdih pemalang-new.xlsx  File  \n",
       "34  SupplementaryFile1.HPRCy1v2genbank.self.s50k.l...  File  \n",
       "35                     SupplementaryFile4.eid0900.tsv  File  \n",
       "36               SupplementaryFile7.chm13v2.PRDM9.tsv  File  \n",
       "37  SupplementaryFile8.chrACRO+refs.pq_contigs.1kb...  File  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d909c54c-401a-4124-b4a3-5d803bb0ef5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             \n",
       "1     10118192\n",
       "2     10118192\n",
       "3     10118192\n",
       "4     10118192\n",
       "5     10118192\n",
       "6     10118192\n",
       "7     10606483\n",
       "8     10606483\n",
       "9     10606483\n",
       "10    10606483\n",
       "11    11165918\n",
       "12    11165918\n",
       "13    11165918\n",
       "14    11165918\n",
       "15    13236575\n",
       "16     3520917\n",
       "17     3520917\n",
       "18     3520917\n",
       "19     3520917\n",
       "20     3520917\n",
       "21     3520917\n",
       "22     3520917\n",
       "23     5042194\n",
       "24     5770442\n",
       "25     5770442\n",
       "26     5770442\n",
       "27     5770442\n",
       "28     5770442\n",
       "29     6984998\n",
       "30     6984998\n",
       "31     6984998\n",
       "32     7326500\n",
       "33     7576974\n",
       "34     7692555\n",
       "35     7692555\n",
       "36     7692555\n",
       "37     7692555\n",
       "Name: Subdirectory_Level_1, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Subdirectory_Level_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0d3029-88eb-42a7-b470-8d43de3365ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[df['Subdirectory_Level_2'].str.contains('mondrian')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41bbada4-509b-47d7-b62a-244099dbbf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "filetime = datetime.now()\n",
    "filetime = filetime.strftime('%Y-%m-%d_%I-%M_%p')\n",
    "df.to_csv(f'file_inventory_{filetime}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ac67aa-cc51-4a9e-b31a-eb44d4ea6bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Google Gemini Response, Flash 2.5, 2025-06-26\n",
    "# Prompts:\n",
    "# 1: Can you write a short Python script using pathlib to walk through a directory and its subdirectories, creating columns in a Pandas dataframe for directory, subdirectories, and files?\n",
    "# 2: I don't need to create a dummy directory, can you remove that part?\n",
    "# 3: I may have two levels of subdirectories. Can you modify the script to put each level of subdirectory in its own column?\n",
    "# 4: I do not need to store rows of type Directory in my dataframe. Can you remove that part of the script?\n",
    "\n",
    "# import pandas as pd\n",
    "# from pathlib import Path\n",
    "# import os\n",
    "# import tempfile\n",
    "# import shutil\n",
    "\n",
    "# def walk_directory_to_dataframe(directory_path: str) -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Walks through a specified directory and its subdirectories,\n",
    "#     creating a Pandas DataFrame with columns for the root directory,\n",
    "#     individual subdirectory levels (e.g., 'Subdirectory_Level_1', 'Subdirectory_Level_2'),\n",
    "#     and files. Only files are included in the DataFrame.\n",
    "\n",
    "#     Args:\n",
    "#         directory_path (str): The path to the root directory to traverse.\n",
    "\n",
    "#     Returns:\n",
    "#         pd.DataFrame: A DataFrame containing the file structure.\n",
    "#                       Columns will include 'Directory', dynamically generated\n",
    "#                       'Subdirectory_Level_X' columns, 'File', and 'Type' (always 'File').\n",
    "#     \"\"\"\n",
    "#     path_obj = Path(directory_path)\n",
    "#     if not path_obj.exists():\n",
    "#         print(f\"Error: The specified directory '{directory_path}' does not exist.\")\n",
    "#         return pd.DataFrame() # Return an empty DataFrame\n",
    "\n",
    "#     if not path_obj.is_dir():\n",
    "#         print(f\"Error: The specified path '{directory_path}' is not a directory.\")\n",
    "#         return pd.DataFrame() # Return an empty DataFrame\n",
    "\n",
    "#     data = []\n",
    "#     max_depth = 0\n",
    "\n",
    "#     # Iterate through all files and directories recursively\n",
    "#     # We use rglob('*') to find all items, but only process files.\n",
    "#     for item in path_obj.rglob('*'):\n",
    "#         if item.is_file(): # Only process files\n",
    "#             row_data = {\n",
    "#                 'Directory': str(path_obj.name), # The name of the root directory being scanned\n",
    "#                 'File': item.name,              # The name of the file\n",
    "#                 'Type': 'File'                  # Type is always 'File'\n",
    "#             }\n",
    "\n",
    "#             current_level_parts = [] # To store the components of the subdirectory path for the current file\n",
    "\n",
    "#             # For a file, the subdirectory levels are determined by its parent's path relative to the root\n",
    "#             if item.parent != path_obj: # Check if the parent is not the root directory itself\n",
    "#                 relative_parent_path = item.parent.relative_to(path_obj)\n",
    "#                 current_level_parts = list(relative_parent_path.parts)\n",
    "\n",
    "#             # Update the maximum depth found across all items to know how many level columns to create\n",
    "#             max_depth = max(max_depth, len(current_level_parts))\n",
    "\n",
    "#             # Assign each part of the subdirectory path to its respective 'Subdirectory_Level_X' column\n",
    "#             for i, part in enumerate(current_level_parts):\n",
    "#                 row_data[f'Subdirectory_Level_{i + 1}'] = part\n",
    "\n",
    "#             data.append(row_data)\n",
    "\n",
    "#     # If no data was collected (e.g., empty directory or only directories), return an empty DataFrame\n",
    "#     if not data:\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     # Create the initial DataFrame from the collected data\n",
    "#     df = pd.DataFrame(data)\n",
    "\n",
    "#     # Ensure all potential 'Subdirectory_Level_X' columns exist and fill any missing values (NaNs)\n",
    "#     # with empty strings for shallower paths (e.g., files directly in root)\n",
    "#     for i in range(1, max_depth + 1):\n",
    "#         col_name = f'Subdirectory_Level_{i}'\n",
    "#         if col_name not in df.columns:\n",
    "#             df[col_name] = '' # Add column if it was not present in any row data\n",
    "#         df[col_name] = df[col_name].fillna('') # Fill NaN values with empty strings\n",
    "\n",
    "#     # Define the desired order of columns in the final DataFrame\n",
    "#     ordered_columns = ['Directory']\n",
    "#     for i in range(1, max_depth + 1):\n",
    "#         ordered_columns.append(f'Subdirectory_Level_{i}')\n",
    "#     ordered_columns.extend(['File', 'Type'])\n",
    "\n",
    "#     # Filter the ordered_columns list to only include columns that actually exist in the DataFrame\n",
    "#     df = df[[col for col in ordered_columns if col in df.columns]]\n",
    "\n",
    "#     # Sort the DataFrame for better readability.\n",
    "#     # The sort keys are dynamically constructed based on the available subdirectory level columns.\n",
    "#     if not df.empty:\n",
    "#         sort_by_cols = ['Directory']\n",
    "#         for i in range(1, max_depth + 1):\n",
    "#             if f'Subdirectory_Level_{i}' in df.columns:\n",
    "#                 sort_by_cols.append(f'Subdirectory_Level_{i}')\n",
    "#         sort_by_cols.append('File')\n",
    "#         df = df.sort_values(by=sort_by_cols).reset_index(drop=True)\n",
    "\n",
    "#     return df\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     # This block creates a temporary directory and populates it with a multi-level structure\n",
    "#     # to demonstrate the script's functionality without affecting your actual file system.\n",
    "#     with tempfile.TemporaryDirectory() as tmpdir:\n",
    "#         base_demo_path = Path(tmpdir) / \"my_multi_level_root\"\n",
    "#         base_demo_path.mkdir(parents=True, exist_ok=True) # Ensure the root for demo exists\n",
    "\n",
    "#         # Creating a sample multi-level directory and file structure\n",
    "#         (base_demo_path / \"level1_dir_A\").mkdir()\n",
    "#         (base_demo_path / \"level1_dir_B\").mkdir()\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"file_A1.txt\").write_text(\"Content A1\")\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"level2_dir_AA\").mkdir() # This directory itself won't be in df\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"level2_dir_AA\" / \"file_AA1.log\").write_text(\"Content AA1\")\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"level2_dir_AA\" / \"level3_dir_AAA\").mkdir() # This directory itself won't be in df\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"level2_dir_AA\" / \"level3_dir_AAA\" / \"data.csv\").write_text(\"data,1,2,3\")\n",
    "#         (base_demo_path / \"level1_dir_B\" / \"file_B1.jpg\").write_text(\"Binary data B1\")\n",
    "#         (base_demo_path / \"root_file.txt\").write_text(\"Root file content\")\n",
    "#         (base_demo_path / \"another_root_file.md\").write_text(\"Another root file.\")\n",
    "#         (base_demo_path / \"single_level_dir\").mkdir() # This directory itself won't be in df\n",
    "#         (base_demo_path / \"single_level_dir\" / \"single_file.json\").write_text(\"{}\")\n",
    "#         (base_demo_path / \"level1_dir_A\" / \"level2_dir_AA\" / \"empty_dir\").mkdir() # Empty dir, won't be in df\n",
    "\n",
    "#         target_directory = str(base_demo_path)\n",
    "#         print(f\"\\n--- Walking through the directory: {target_directory} and creating DataFrame with only files ---\")\n",
    "#         df_result = walk_directory_to_dataframe(target_directory)\n",
    "\n",
    "#         if not df_result.empty:\n",
    "#             print(\"\\nDataFrame created successfully:\")\n",
    "#             # Using to_string() to display the full DataFrame without truncation in the console\n",
    "#             print(df_result.to_string())\n",
    "#         else:\n",
    "#             print(\"\\nNo data found or DataFrame is empty.\")\n",
    "#             print(\"Note: This could happen if the directory contains only subdirectories and no files.\")\n",
    "\n",
    "\n",
    "#         print(f\"\\nTemporary directory '{tmpdir}' and its contents will be removed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef221ec-ad46-488b-b1d0-96d56d8e34bd",
   "metadata": {},
   "source": [
    "## Initial attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b307106-16cc-49c6-b88c-c3328ebcabc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://appdividend.com/list-of-files-in-directory-and-subdirectories-in-python/\n",
    "file_list=[]\n",
    "for dirpath, dirnames, filenames in os.walk('outputs'):\n",
    "    #print(dirpath,dirnames,filenames)\n",
    "    file_dict={}\n",
    "    for filename in filenames:\n",
    "        print(dirpath,filename)\n",
    "        file_dict['dirname'] = dirpath\n",
    "        file_dict['filename'] = filename\n",
    "        print(file_dict)\n",
    "        file_list.append(file_dict)\n",
    "        #print(os.path.join(dirpath, filename))\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2d886-463a-41cb-8389-f556fa75f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory = pd.DataFrame(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9df9618-43a7-443c-8fb4-a89037bec095",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712adbbd-0870-447f-84dd-0369c3f77d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory['dirname'].str.split('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d99e02-8ea9-463a-be57-a07ff17fec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.statology.org/pandas-split-column/\n",
    "file_inventory[['dirname','subdir']] = file_inventory['dirname'].str.split('/', n=1, expand=True)\n",
    "#df['A'].str.split(',', 1, expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57969b6-5553-411b-9653-116cb6d945cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60caedc6-c0b0-456d-add4-c499dbda589a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python/python-list-all-files-in-directory-and-subdirectories/\n",
    "from pathlib import Path\n",
    "\n",
    "def list_files_pathlib(path=Path('.')):\n",
    "    for entry in path.iterdir():\n",
    "        if entry.is_file():\n",
    "            print(entry)\n",
    "        elif entry.is_dir():\n",
    "            list_files_pathlib(entry)\n",
    "\n",
    "# Specify the directory path you want to start from\n",
    "directory_path = Path('outputs')\n",
    "list_files_pathlib(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7c6d19-91fb-4df8-9793-ed9b8b45d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/python/python-list-all-files-in-directory-and-subdirectories/\n",
    "from pathlib import Path\n",
    "path = Path('outputs')\n",
    "\n",
    "#def list_files_pathlib(path=Path('.')):\n",
    "for entry in path.iterdir():\n",
    "    print(entry.parent())\n",
    "    # if entry.is_file():\n",
    "    #     print(entry)\n",
    "    # elif entry.is_dir():\n",
    "    #     list_files_pathlib(entry)\n",
    "\n",
    "# # Specify the directory path you want to start from\n",
    "# directory_path = Path('outputs')\n",
    "# list_files_pathlib(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d76032-9d38-4cb8-b3f8-cc7c2f33faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "#def list_files(directory):\n",
    "path = Path('outputs')\n",
    "# rglob pattern '*' matches all files and directories\n",
    "for file_path in path.rglob('*'):\n",
    "    if file_path.is_file():  # Check if it's a file\n",
    "        print(file_path)\n",
    "    if file_path.is_dir():\n",
    "        print(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea02a914-c216-483f-b8a2-69ca98a3e40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Google Gemini Flash 2.5 version, modified\n",
    "\n",
    "path_obj = Path('outputs')\n",
    "# if not path_obj.exists():\n",
    "#     print(f\"Error: The specified directory '{directory_path}' does not exist.\")\n",
    "#     return pd.DataFrame() # Return an empty DataFrame\n",
    "\n",
    "# if not path_obj.is_dir():\n",
    "#     print(f\"Error: The specified path '{directory_path}' is not a directory.\")\n",
    "#     return pd.DataFrame() # Return an empty DataFrame\n",
    "\n",
    "data = []\n",
    "\n",
    "# Iterate through all files and directories recursively\n",
    "for item in path_obj.rglob('*'): # rglob('*') iterates over all contents recursively\n",
    "    # if item.is_dir():\n",
    "    #     dir_name = item.name\n",
    "    #     parent_dir = item.parent.relative_to(path_obj) if item.parent != path_obj else Path('')\n",
    "    #     data.append({\n",
    "    #         'Directory': str(path_obj.name),\n",
    "    #         'Subdirectory': str(parent_dir / dir_name) if parent_dir else dir_name,\n",
    "    #         'File': '',\n",
    "    #         'Type': 'Directory'\n",
    "    #     })\n",
    "    if item.is_file():\n",
    "        file_name = item.name\n",
    "        parent_dir = item.parent.relative_to(path_obj) if item.parent != path_obj else Path('')\n",
    "        data.append({\n",
    "            'dir': str(path_obj.name),\n",
    "            'subdir': str(parent_dir),\n",
    "            'filename': file_name,\n",
    "            'type': 'File'\n",
    "        })\n",
    "\n",
    "# Sort data for better readability (optional)\n",
    "df = pd.DataFrame(data)\n",
    "df = df.sort_values(by=['dir', 'subdir', 'filename']).reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
